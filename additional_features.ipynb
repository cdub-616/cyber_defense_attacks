{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Additional features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Libraries and functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "    \n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Convert training/test files to pandas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_df.shape: (82332, 45)\n",
      "testing_set_df.shape: (175341, 45)\n"
     ]
    }
   ],
   "source": [
    "training_set_df = pd.read_csv('data/UNSW_NB15_testing-set.csv')\n",
    "testing_set_df = pd.read_csv('data/UNSW_NB15_training-set.csv')\n",
    "print('training_set_df.shape:', training_set_df.shape)\n",
    "print('testing_set_df.shape:', testing_set_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Remove rows with missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_df.shape: (82332, 45)\n",
      "testing_set_df.shape: (175341, 45)\n"
     ]
    }
   ],
   "source": [
    "training_set_df.dropna(inplace=True)\n",
    "testing_set_df.dropna(inplace=True)\n",
    "print('training_set_df.shape:', training_set_df.shape)\n",
    "print('testing_set_df.shape:', testing_set_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Remove rows with normal activity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_df.shape: (45332, 45)\n",
      "testing_set_df.shape: (119341, 45)\n"
     ]
    }
   ],
   "source": [
    "training_set_df = training_set_df[training_set_df['label'] != 0]\n",
    "testing_set_df = testing_set_df[testing_set_df['label'] != 0]\n",
    "print('training_set_df.shape:', training_set_df.shape)\n",
    "print('testing_set_df.shape:', testing_set_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Remove unnecessary columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_df.shape: (45332, 43)\n",
      "testing_set_df.shape: (119341, 43)\n"
     ]
    }
   ],
   "source": [
    "training_set_df.drop(['id', 'label'], axis=1, inplace=True)\n",
    "testing_set_df.drop(['id', 'label'], axis=1, inplace=True)\n",
    "print('training_set_df.shape:', training_set_df.shape)\n",
    "print('testing_set_df.shape:', testing_set_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Obtain map of index value to category value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_to_category: {0: 'Reconnaissance', 1: 'Backdoor', 2: 'DoS', 3: 'Exploits', 4: 'Analysis', 5: 'Fuzzers', 6: 'Worms', 7: 'Shellcode', 8: 'Generic'}\n"
     ]
    }
   ],
   "source": [
    "unique_categories = training_set_df['attack_cat'].unique()\n",
    "index_to_category = {index: category for index, category in enumerate(unique_categories)}\n",
    "print('index_to_category:', index_to_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Encode categorical features index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['attack_cat', 'is_ftp_login', 'is_sm_ips_ports'] #They see these as integers, not binary objects\n",
    "\n",
    "training_df = training_set_df.copy()\n",
    "testing_df = testing_set_df.copy()\n",
    "\n",
    "for column in training_df.select_dtypes(include=['object']).columns: \n",
    "    encode_text_index(training_df, column)\n",
    "    encode_text_index(testing_df, column)\n",
    "\n",
    "for column in binary_columns:\n",
    "    encode_text_index(training_df, column)\n",
    "    encode_text_index(testing_df, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Normalize numeric features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in training_set_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if column not in binary_columns:\n",
    "        encode_numeric_zscore(training_df, column)\n",
    "        encode_numeric_zscore(testing_df, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save dataframes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_pickle('data/training_df_additional.pkl');\n",
    "testing_df.to_pickle('data/testing_df_additional.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load dataframes (optional starting point)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_pickle('./data/training_df_additional.pkl')\n",
    "testing_df = pd.read_pickle('./data/testing_df_additional.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Use dataframe to configure x,y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['attack_cat'] = training_df['attack_cat'].astype('category')\n",
    "testing_df['attack_cat'] = testing_df['attack_cat'].astype('category')\n",
    "x_train, y_train = to_xy(training_df, 'attack_cat')\n",
    "x_test, y_test = to_xy(testing_df, 'attack_cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Shape*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (45332, 42)\n",
      "y_train shape: (45332,)\n",
      "x_test shape: (119341, 42)\n",
      "y_test shape: (119341,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Reshape x's*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rows = x_train.shape[0]\n",
    "x_cols = x_train.shape[1]\n",
    "x_test_rows = x_test.shape[0]\n",
    "x_train = x_train.reshape((x_train_rows, 1, x_cols, 1))\n",
    "x_test = x_test.reshape((x_test_rows, 1, x_cols, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *x_train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (45332, 1, 42, 1)\n",
      "[[[[-1.5427328e-02]\n",
      "   [ 7.5000000e+01]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-7.2732645e-01]\n",
      "   [-8.3137202e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-1.5427328e-02]\n",
      "   [ 7.5000000e+01]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-7.2732645e-01]\n",
      "   [-8.3137202e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-1.5427328e-02]\n",
      "   [ 7.5000000e+01]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-7.2732645e-01]\n",
      "   [-8.3137202e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 3.7732542e+00]\n",
      "   [ 1.1500000e+02]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-7.2732645e-01]\n",
      "   [-4.5713210e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-7.2383285e-02]\n",
      "   [ 1.0900000e+02]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-7.2732645e-01]\n",
      "   [-5.3198010e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-1.2798063e-01]\n",
      "   [ 1.0900000e+02]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-6.3165802e-01]\n",
      "   [-6.0682809e-01]\n",
      "   [ 0.0000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print (x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *x_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (119341, 1, 42, 1)\n",
      "[[[[-2.1380657e-01]\n",
      "   [ 1.9000000e+01]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-6.7011690e-01]\n",
      "   [-5.6223780e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-2.1380657e-01]\n",
      "   [ 5.0000000e+01]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-6.7011690e-01]\n",
      "   [-3.1350216e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-2.1380657e-01]\n",
      "   [ 1.1000000e+01]\n",
      "   [ 0.0000000e+00]\n",
      "   ...\n",
      "   [-7.7625304e-01]\n",
      "   [-3.9641404e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-2.1380657e-01]\n",
      "   [ 1.1500000e+02]\n",
      "   [ 2.0000000e+00]\n",
      "   ...\n",
      "   [-5.6398076e-01]\n",
      "   [ 1.0105731e-01]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-2.1380657e-01]\n",
      "   [ 1.1500000e+02]\n",
      "   [ 2.0000000e+00]\n",
      "   ...\n",
      "   [ 2.3016953e+00]\n",
      "   [ 1.5934714e+00]\n",
      "   [ 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[-2.1380657e-01]\n",
      "   [ 1.1500000e+02]\n",
      "   [ 2.0000000e+00]\n",
      "   ...\n",
      "   [ 2.3016953e+00]\n",
      "   [ 1.5934714e+00]\n",
      "   [ 0.0000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "print('x_test shape:', x_test.shape)\n",
    "print (x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Convert y's to one-hot encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_classes: 9\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = len(index_to_category)\n",
    "print('number_of_classes:', number_of_classes)\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, number_of_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *y_train_one_hot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_one_hot shape: (45332, 9)\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('y_train_one_hot shape:', y_train_one_hot.shape)\n",
    "print(y_train_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *y_test_one_hot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_one_hot shape: (119341, 9)\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('y_test_one_hot shape:', y_test_one_hot.shape)\n",
    "print (y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model:  relu and adam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1417/1417 - 65s - loss: 0.6831 - accuracy: 0.7514 - val_loss: 0.7484 - val_accuracy: 0.7281 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1417/1417 - 65s - loss: 0.5690 - accuracy: 0.7828 - val_loss: 0.7396 - val_accuracy: 0.7446 - 65s/epoch - 46ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 65s - loss: 0.5372 - accuracy: 0.7900 - val_loss: 0.7355 - val_accuracy: 0.7443 - 65s/epoch - 46ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.5166 - accuracy: 0.7952 - val_loss: 0.7736 - val_accuracy: 0.7240 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 64s - loss: 0.5049 - accuracy: 0.7977 - val_loss: 0.7804 - val_accuracy: 0.7221 - 64s/epoch - 45ms/step\n",
      "Epoch 5: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 0.6737 - accuracy: 0.7532 - val_loss: 0.7535 - val_accuracy: 0.7166 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.5675 - accuracy: 0.7840 - val_loss: 0.7465 - val_accuracy: 0.7371 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 65s - loss: 0.5350 - accuracy: 0.7907 - val_loss: 0.7491 - val_accuracy: 0.7256 - 65s/epoch - 46ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 66s - loss: 0.5178 - accuracy: 0.7958 - val_loss: 0.7090 - val_accuracy: 0.7431 - 66s/epoch - 47ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 65s - loss: 0.5042 - accuracy: 0.7946 - val_loss: 0.7582 - val_accuracy: 0.7298 - 65s/epoch - 46ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 64s - loss: 0.4912 - accuracy: 0.8032 - val_loss: 0.7287 - val_accuracy: 0.7438 - 64s/epoch - 45ms/step\n",
      "Epoch 6: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 0.6683 - accuracy: 0.7545 - val_loss: 0.7643 - val_accuracy: 0.7328 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 65s - loss: 0.5687 - accuracy: 0.7819 - val_loss: 0.7859 - val_accuracy: 0.7178 - 65s/epoch - 46ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.5365 - accuracy: 0.7904 - val_loss: 0.7440 - val_accuracy: 0.7327 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.5162 - accuracy: 0.7949 - val_loss: 0.7480 - val_accuracy: 0.7352 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 66s - loss: 0.5015 - accuracy: 0.7994 - val_loss: 0.7054 - val_accuracy: 0.7450 - 66s/epoch - 46ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 64s - loss: 0.4934 - accuracy: 0.8011 - val_loss: 0.7206 - val_accuracy: 0.7392 - 64s/epoch - 45ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 64s - loss: 0.4831 - accuracy: 0.8048 - val_loss: 0.7673 - val_accuracy: 0.7289 - 64s/epoch - 45ms/step\n",
      "Epoch 7: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 0.6766 - accuracy: 0.7531 - val_loss: 0.7789 - val_accuracy: 0.7088 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 62s - loss: 0.5686 - accuracy: 0.7826 - val_loss: 0.7959 - val_accuracy: 0.7159 - 62s/epoch - 44ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 62s - loss: 0.5356 - accuracy: 0.7908 - val_loss: 0.7369 - val_accuracy: 0.7214 - 62s/epoch - 44ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 62s - loss: 0.5146 - accuracy: 0.7963 - val_loss: 0.6985 - val_accuracy: 0.7381 - 62s/epoch - 44ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 62s - loss: 0.5036 - accuracy: 0.7996 - val_loss: 0.7739 - val_accuracy: 0.7240 - 62s/epoch - 44ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 62s - loss: 0.4936 - accuracy: 0.8006 - val_loss: 0.7223 - val_accuracy: 0.7427 - 62s/epoch - 44ms/step\n",
      "Epoch 6: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "1417/1417 - 63s - loss: 0.6818 - accuracy: 0.7511 - val_loss: 0.7696 - val_accuracy: 0.7144 - 63s/epoch - 45ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 61s - loss: 0.5669 - accuracy: 0.7823 - val_loss: 0.7213 - val_accuracy: 0.7282 - 61s/epoch - 43ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 62s - loss: 0.5376 - accuracy: 0.7909 - val_loss: 0.7170 - val_accuracy: 0.7481 - 62s/epoch - 44ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 63s - loss: 0.5204 - accuracy: 0.7926 - val_loss: 0.7727 - val_accuracy: 0.7300 - 63s/epoch - 44ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 63s - loss: 0.5045 - accuracy: 0.7984 - val_loss: 0.7309 - val_accuracy: 0.7470 - 63s/epoch - 45ms/step\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"best_weights_additional.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(1, x_cols, 1), padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')\n",
    "    model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot),callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model:  sigmoid and adam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 1.0473 - accuracy: 0.6267 - val_loss: 0.8517 - val_accuracy: 0.7054 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.7118 - accuracy: 0.7354 - val_loss: 0.8151 - val_accuracy: 0.6836 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.6632 - accuracy: 0.7504 - val_loss: 0.8210 - val_accuracy: 0.6809 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.6391 - accuracy: 0.7585 - val_loss: 0.7876 - val_accuracy: 0.7073 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 64s - loss: 0.6244 - accuracy: 0.7652 - val_loss: 0.7611 - val_accuracy: 0.7336 - 64s/epoch - 45ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 64s - loss: 0.6094 - accuracy: 0.7701 - val_loss: 0.8084 - val_accuracy: 0.7192 - 64s/epoch - 45ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 64s - loss: 0.6037 - accuracy: 0.7713 - val_loss: 0.7995 - val_accuracy: 0.7262 - 64s/epoch - 45ms/step\n",
      "Epoch 7: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "1417/1417 - 77s - loss: 1.2100 - accuracy: 0.5633 - val_loss: 0.8418 - val_accuracy: 0.6901 - 77s/epoch - 55ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 66s - loss: 0.7070 - accuracy: 0.7371 - val_loss: 0.8628 - val_accuracy: 0.6659 - 66s/epoch - 46ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 70s - loss: 0.6562 - accuracy: 0.7530 - val_loss: 0.8958 - val_accuracy: 0.6793 - 70s/epoch - 49ms/step\n",
      "Epoch 3: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 1.1558 - accuracy: 0.5875 - val_loss: 0.8567 - val_accuracy: 0.6986 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.7183 - accuracy: 0.7337 - val_loss: 0.8086 - val_accuracy: 0.7094 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.6664 - accuracy: 0.7508 - val_loss: 0.7806 - val_accuracy: 0.7186 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.6400 - accuracy: 0.7598 - val_loss: 0.8275 - val_accuracy: 0.6998 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 64s - loss: 0.6242 - accuracy: 0.7657 - val_loss: 0.8411 - val_accuracy: 0.7057 - 64s/epoch - 46ms/step\n",
      "Epoch 5: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 1.2479 - accuracy: 0.5462 - val_loss: 0.8809 - val_accuracy: 0.6748 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.7092 - accuracy: 0.7371 - val_loss: 0.8309 - val_accuracy: 0.6824 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.6563 - accuracy: 0.7538 - val_loss: 0.7673 - val_accuracy: 0.7122 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.6295 - accuracy: 0.7640 - val_loss: 0.7601 - val_accuracy: 0.7189 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 65s - loss: 0.6153 - accuracy: 0.7688 - val_loss: 0.7517 - val_accuracy: 0.7331 - 65s/epoch - 46ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 65s - loss: 0.6045 - accuracy: 0.7720 - val_loss: 0.7530 - val_accuracy: 0.7427 - 65s/epoch - 46ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 64s - loss: 0.5931 - accuracy: 0.7741 - val_loss: 0.7627 - val_accuracy: 0.7358 - 64s/epoch - 45ms/step\n",
      "Epoch 7: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "1417/1417 - 64s - loss: 1.1020 - accuracy: 0.6070 - val_loss: 0.8607 - val_accuracy: 0.6758 - 64s/epoch - 45ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.7148 - accuracy: 0.7324 - val_loss: 0.7934 - val_accuracy: 0.7194 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.6682 - accuracy: 0.7483 - val_loss: 0.8155 - val_accuracy: 0.7068 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.6381 - accuracy: 0.7602 - val_loss: 0.8052 - val_accuracy: 0.6957 - 64s/epoch - 45ms/step\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"models/best_weights_additional.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='sigmoid', input_shape=(1, x_cols, 1), padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='sigmoid', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')\n",
    "    model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot),callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model:  tanh and adam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "1417/1417 - 67s - loss: 0.8058 - accuracy: 0.7189 - val_loss: 0.8287 - val_accuracy: 0.7166 - 67s/epoch - 47ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 63s - loss: 0.7230 - accuracy: 0.7408 - val_loss: 0.8065 - val_accuracy: 0.7214 - 63s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.7085 - accuracy: 0.7447 - val_loss: 0.8685 - val_accuracy: 0.7012 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 63s - loss: 0.6999 - accuracy: 0.7505 - val_loss: 0.9007 - val_accuracy: 0.6761 - 63s/epoch - 44ms/step\n",
      "Epoch 4: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "1417/1417 - 64s - loss: 0.8008 - accuracy: 0.7196 - val_loss: 0.8782 - val_accuracy: 0.6816 - 64s/epoch - 45ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 65s - loss: 0.7245 - accuracy: 0.7383 - val_loss: 0.8189 - val_accuracy: 0.7101 - 65s/epoch - 46ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.7066 - accuracy: 0.7453 - val_loss: 0.8246 - val_accuracy: 0.7170 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 65s - loss: 0.6904 - accuracy: 0.7524 - val_loss: 0.7922 - val_accuracy: 0.7059 - 65s/epoch - 46ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 66s - loss: 0.6865 - accuracy: 0.7541 - val_loss: 0.8125 - val_accuracy: 0.7308 - 66s/epoch - 46ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 64s - loss: 0.6815 - accuracy: 0.7573 - val_loss: 0.7692 - val_accuracy: 0.7202 - 64s/epoch - 45ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 64s - loss: 0.6783 - accuracy: 0.7593 - val_loss: 0.8327 - val_accuracy: 0.7068 - 64s/epoch - 45ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 64s - loss: 0.6795 - accuracy: 0.7596 - val_loss: 0.8077 - val_accuracy: 0.7261 - 64s/epoch - 45ms/step\n",
      "Epoch 8: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 0.8000 - accuracy: 0.7222 - val_loss: 0.9960 - val_accuracy: 0.6289 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.7170 - accuracy: 0.7389 - val_loss: 0.9222 - val_accuracy: 0.6664 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 64s - loss: 0.7014 - accuracy: 0.7483 - val_loss: 0.8040 - val_accuracy: 0.7165 - 64s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.6920 - accuracy: 0.7515 - val_loss: 0.7956 - val_accuracy: 0.7236 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 64s - loss: 0.6777 - accuracy: 0.7549 - val_loss: 0.8642 - val_accuracy: 0.6889 - 64s/epoch - 45ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 64s - loss: 0.6786 - accuracy: 0.7552 - val_loss: 0.8183 - val_accuracy: 0.7193 - 64s/epoch - 45ms/step\n",
      "Epoch 6: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "1417/1417 - 65s - loss: 0.8066 - accuracy: 0.7197 - val_loss: 0.9590 - val_accuracy: 0.6777 - 65s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.7232 - accuracy: 0.7384 - val_loss: 0.8602 - val_accuracy: 0.6859 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 63s - loss: 0.7034 - accuracy: 0.7470 - val_loss: 0.8422 - val_accuracy: 0.7077 - 63s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.6884 - accuracy: 0.7531 - val_loss: 0.8510 - val_accuracy: 0.7044 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 66s - loss: 0.6871 - accuracy: 0.7531 - val_loss: 0.8929 - val_accuracy: 0.6730 - 66s/epoch - 46ms/step\n",
      "Epoch 5: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "1417/1417 - 66s - loss: 0.8082 - accuracy: 0.7173 - val_loss: 0.8569 - val_accuracy: 0.6956 - 66s/epoch - 46ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 64s - loss: 0.7229 - accuracy: 0.7391 - val_loss: 0.8949 - val_accuracy: 0.6867 - 64s/epoch - 45ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 63s - loss: 0.7031 - accuracy: 0.7455 - val_loss: 0.8543 - val_accuracy: 0.6831 - 63s/epoch - 45ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 64s - loss: 0.6986 - accuracy: 0.7514 - val_loss: 0.9514 - val_accuracy: 0.6668 - 64s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 64s - loss: 0.6912 - accuracy: 0.7530 - val_loss: 0.8057 - val_accuracy: 0.7292 - 64s/epoch - 45ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 64s - loss: 0.6846 - accuracy: 0.7570 - val_loss: 0.7805 - val_accuracy: 0.7237 - 64s/epoch - 45ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 64s - loss: 0.6883 - accuracy: 0.7584 - val_loss: 0.7951 - val_accuracy: 0.7229 - 64s/epoch - 45ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 64s - loss: 0.6965 - accuracy: 0.7556 - val_loss: 0.7976 - val_accuracy: 0.7318 - 64s/epoch - 45ms/step\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"models/best_weights_additional.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='tanh', input_shape=(1, x_cols, 1), padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')\n",
    "    model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot),callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model:  relu and sgd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "1417/1417 - 28s - loss: 1.1078 - accuracy: 0.6154 - val_loss: 0.9816 - val_accuracy: 0.6308 - 28s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 0.7936 - accuracy: 0.7207 - val_loss: 0.9461 - val_accuracy: 0.6756 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 0.6965 - accuracy: 0.7521 - val_loss: 0.8344 - val_accuracy: 0.6989 - 27s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 27s - loss: 0.6585 - accuracy: 0.7616 - val_loss: 0.8031 - val_accuracy: 0.7031 - 27s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 27s - loss: 0.6355 - accuracy: 0.7648 - val_loss: 0.7905 - val_accuracy: 0.7256 - 27s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 27s - loss: 0.6201 - accuracy: 0.7696 - val_loss: 0.7910 - val_accuracy: 0.7099 - 27s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 29s - loss: 0.6065 - accuracy: 0.7718 - val_loss: 0.7684 - val_accuracy: 0.7308 - 29s/epoch - 20ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 27s - loss: 0.5979 - accuracy: 0.7731 - val_loss: 0.7833 - val_accuracy: 0.7114 - 27s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 27s - loss: 0.5902 - accuracy: 0.7761 - val_loss: 0.7669 - val_accuracy: 0.7301 - 27s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "1417/1417 - 27s - loss: 0.5833 - accuracy: 0.7787 - val_loss: 0.8007 - val_accuracy: 0.7103 - 27s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "1417/1417 - 27s - loss: 0.5785 - accuracy: 0.7789 - val_loss: 0.7973 - val_accuracy: 0.7230 - 27s/epoch - 19ms/step\n",
      "Epoch 11: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "1417/1417 - 27s - loss: 1.1142 - accuracy: 0.6108 - val_loss: 0.9569 - val_accuracy: 0.6464 - 27s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 26s - loss: 0.8078 - accuracy: 0.7139 - val_loss: 0.8552 - val_accuracy: 0.6981 - 26s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 0.7065 - accuracy: 0.7468 - val_loss: 0.8066 - val_accuracy: 0.7197 - 27s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 26s - loss: 0.6706 - accuracy: 0.7568 - val_loss: 0.8443 - val_accuracy: 0.6925 - 26s/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 26s - loss: 0.6468 - accuracy: 0.7623 - val_loss: 0.7879 - val_accuracy: 0.7192 - 26s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 27s - loss: 0.6295 - accuracy: 0.7664 - val_loss: 0.7826 - val_accuracy: 0.7231 - 27s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 27s - loss: 0.6170 - accuracy: 0.7703 - val_loss: 0.8051 - val_accuracy: 0.6987 - 27s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 27s - loss: 0.6071 - accuracy: 0.7714 - val_loss: 0.7757 - val_accuracy: 0.7225 - 27s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 27s - loss: 0.5991 - accuracy: 0.7732 - val_loss: 0.7530 - val_accuracy: 0.7208 - 27s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "1417/1417 - 27s - loss: 0.5920 - accuracy: 0.7740 - val_loss: 0.7813 - val_accuracy: 0.7107 - 27s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "1417/1417 - 27s - loss: 0.5854 - accuracy: 0.7768 - val_loss: 0.7885 - val_accuracy: 0.7214 - 27s/epoch - 19ms/step\n",
      "Epoch 11: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "1417/1417 - 27s - loss: 1.1286 - accuracy: 0.6042 - val_loss: 0.9772 - val_accuracy: 0.6018 - 27s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 28s - loss: 0.8065 - accuracy: 0.7145 - val_loss: 0.8551 - val_accuracy: 0.7016 - 28s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 0.7041 - accuracy: 0.7483 - val_loss: 0.8434 - val_accuracy: 0.6909 - 27s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 27s - loss: 0.6662 - accuracy: 0.7574 - val_loss: 0.8421 - val_accuracy: 0.6988 - 27s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 28s - loss: 0.6440 - accuracy: 0.7624 - val_loss: 0.8090 - val_accuracy: 0.7012 - 28s/epoch - 20ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 27s - loss: 0.6272 - accuracy: 0.7662 - val_loss: 0.8475 - val_accuracy: 0.6985 - 27s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 27s - loss: 0.6142 - accuracy: 0.7706 - val_loss: 0.8333 - val_accuracy: 0.6943 - 27s/epoch - 19ms/step\n",
      "Epoch 7: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "1417/1417 - 28s - loss: 1.1181 - accuracy: 0.6106 - val_loss: 0.9404 - val_accuracy: 0.6659 - 28s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 0.8369 - accuracy: 0.7065 - val_loss: 0.8525 - val_accuracy: 0.7010 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 28s - loss: 0.7089 - accuracy: 0.7463 - val_loss: 0.8235 - val_accuracy: 0.6993 - 28s/epoch - 20ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 28s - loss: 0.6684 - accuracy: 0.7577 - val_loss: 0.8163 - val_accuracy: 0.7097 - 28s/epoch - 20ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 28s - loss: 0.6416 - accuracy: 0.7656 - val_loss: 0.7884 - val_accuracy: 0.7254 - 28s/epoch - 20ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 28s - loss: 0.6259 - accuracy: 0.7652 - val_loss: 0.7894 - val_accuracy: 0.7141 - 28s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 28s - loss: 0.6126 - accuracy: 0.7704 - val_loss: 0.7782 - val_accuracy: 0.7163 - 28s/epoch - 20ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 34s - loss: 0.6023 - accuracy: 0.7741 - val_loss: 0.7980 - val_accuracy: 0.7150 - 34s/epoch - 24ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 30s - loss: 0.5944 - accuracy: 0.7744 - val_loss: 0.7689 - val_accuracy: 0.7288 - 30s/epoch - 21ms/step\n",
      "Epoch 10/100\n",
      "1417/1417 - 28s - loss: 0.5871 - accuracy: 0.7746 - val_loss: 0.7636 - val_accuracy: 0.7195 - 28s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "1417/1417 - 28s - loss: 0.5808 - accuracy: 0.7767 - val_loss: 0.7828 - val_accuracy: 0.7161 - 28s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "1417/1417 - 29s - loss: 0.5741 - accuracy: 0.7814 - val_loss: 0.7878 - val_accuracy: 0.7165 - 29s/epoch - 20ms/step\n",
      "Epoch 12: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "1417/1417 - 29s - loss: 1.1079 - accuracy: 0.6148 - val_loss: 0.9182 - val_accuracy: 0.6688 - 29s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 28s - loss: 0.7942 - accuracy: 0.7195 - val_loss: 0.8807 - val_accuracy: 0.6953 - 28s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 28s - loss: 0.6994 - accuracy: 0.7505 - val_loss: 0.8179 - val_accuracy: 0.7178 - 28s/epoch - 20ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 29s - loss: 0.6607 - accuracy: 0.7610 - val_loss: 0.8423 - val_accuracy: 0.6910 - 29s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 28s - loss: 0.6381 - accuracy: 0.7636 - val_loss: 0.7827 - val_accuracy: 0.7151 - 28s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 28s - loss: 0.6218 - accuracy: 0.7686 - val_loss: 0.7984 - val_accuracy: 0.7003 - 28s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 30s - loss: 0.6097 - accuracy: 0.7719 - val_loss: 0.7740 - val_accuracy: 0.7194 - 30s/epoch - 21ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 29s - loss: 0.5997 - accuracy: 0.7741 - val_loss: 0.8388 - val_accuracy: 0.6898 - 29s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 28s - loss: 0.5903 - accuracy: 0.7765 - val_loss: 0.8025 - val_accuracy: 0.7118 - 28s/epoch - 20ms/step\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"models/best_weights_additional.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(1, x_cols, 1), padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')\n",
    "    model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot),callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model:  sigmoid and sgd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "1417/1417 - 29s - loss: 1.6309 - accuracy: 0.3884 - val_loss: 1.6605 - val_accuracy: 0.3352 - 29s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 30s - loss: 1.5734 - accuracy: 0.4130 - val_loss: 1.6562 - val_accuracy: 0.3352 - 30s/epoch - 21ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 30s - loss: 1.5664 - accuracy: 0.4157 - val_loss: 1.6563 - val_accuracy: 0.3352 - 30s/epoch - 21ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 29s - loss: 1.5624 - accuracy: 0.4164 - val_loss: 1.6523 - val_accuracy: 0.3352 - 29s/epoch - 21ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 28s - loss: 1.5613 - accuracy: 0.4164 - val_loss: 1.6495 - val_accuracy: 0.3352 - 28s/epoch - 20ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 29s - loss: 1.5531 - accuracy: 0.4175 - val_loss: 1.6256 - val_accuracy: 0.3352 - 29s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 28s - loss: 1.5093 - accuracy: 0.4460 - val_loss: 1.4662 - val_accuracy: 0.4966 - 28s/epoch - 20ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 28s - loss: 1.2811 - accuracy: 0.5632 - val_loss: 1.2138 - val_accuracy: 0.5007 - 28s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 28s - loss: 1.1968 - accuracy: 0.5778 - val_loss: 1.1613 - val_accuracy: 0.5089 - 28s/epoch - 20ms/step\n",
      "Epoch 10/100\n",
      "1417/1417 - 28s - loss: 1.1706 - accuracy: 0.5826 - val_loss: 1.1429 - val_accuracy: 0.5113 - 28s/epoch - 20ms/step\n",
      "Epoch 11/100\n",
      "1417/1417 - 28s - loss: 1.1473 - accuracy: 0.5883 - val_loss: 1.0919 - val_accuracy: 0.5611 - 28s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "1417/1417 - 28s - loss: 1.1199 - accuracy: 0.6044 - val_loss: 1.0531 - val_accuracy: 0.6228 - 28s/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "1417/1417 - 28s - loss: 1.0935 - accuracy: 0.6165 - val_loss: 1.0505 - val_accuracy: 0.6019 - 28s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "1417/1417 - 28s - loss: 1.0762 - accuracy: 0.6254 - val_loss: 1.0228 - val_accuracy: 0.6034 - 28s/epoch - 20ms/step\n",
      "Epoch 15/100\n",
      "1417/1417 - 28s - loss: 1.0565 - accuracy: 0.6337 - val_loss: 1.0116 - val_accuracy: 0.6128 - 28s/epoch - 20ms/step\n",
      "Epoch 16/100\n",
      "1417/1417 - 28s - loss: 1.0422 - accuracy: 0.6389 - val_loss: 0.9865 - val_accuracy: 0.6417 - 28s/epoch - 20ms/step\n",
      "Epoch 17/100\n",
      "1417/1417 - 28s - loss: 1.0285 - accuracy: 0.6421 - val_loss: 0.9951 - val_accuracy: 0.6319 - 28s/epoch - 20ms/step\n",
      "Epoch 18/100\n",
      "1417/1417 - 28s - loss: 1.0138 - accuracy: 0.6505 - val_loss: 0.9645 - val_accuracy: 0.6498 - 28s/epoch - 20ms/step\n",
      "Epoch 19/100\n",
      "1417/1417 - 28s - loss: 1.0005 - accuracy: 0.6529 - val_loss: 0.9558 - val_accuracy: 0.6530 - 28s/epoch - 20ms/step\n",
      "Epoch 20/100\n",
      "1417/1417 - 28s - loss: 0.9838 - accuracy: 0.6630 - val_loss: 0.9436 - val_accuracy: 0.6513 - 28s/epoch - 20ms/step\n",
      "Epoch 21/100\n",
      "1417/1417 - 28s - loss: 0.9698 - accuracy: 0.6654 - val_loss: 0.9424 - val_accuracy: 0.6440 - 28s/epoch - 20ms/step\n",
      "Epoch 22/100\n",
      "1417/1417 - 28s - loss: 0.9529 - accuracy: 0.6721 - val_loss: 0.9343 - val_accuracy: 0.6562 - 28s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "1417/1417 - 28s - loss: 0.9334 - accuracy: 0.6795 - val_loss: 0.9107 - val_accuracy: 0.6723 - 28s/epoch - 20ms/step\n",
      "Epoch 24/100\n",
      "1417/1417 - 29s - loss: 0.9112 - accuracy: 0.6868 - val_loss: 0.8997 - val_accuracy: 0.6639 - 29s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "1417/1417 - 28s - loss: 0.8796 - accuracy: 0.6965 - val_loss: 0.8907 - val_accuracy: 0.6639 - 28s/epoch - 20ms/step\n",
      "Epoch 26/100\n",
      "1417/1417 - 28s - loss: 0.8493 - accuracy: 0.7036 - val_loss: 0.8843 - val_accuracy: 0.6648 - 28s/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "1417/1417 - 29s - loss: 0.8157 - accuracy: 0.7128 - val_loss: 0.8733 - val_accuracy: 0.6806 - 29s/epoch - 20ms/step\n",
      "Epoch 28/100\n",
      "1417/1417 - 29s - loss: 0.7951 - accuracy: 0.7148 - val_loss: 0.8845 - val_accuracy: 0.6622 - 29s/epoch - 20ms/step\n",
      "Epoch 29/100\n",
      "1417/1417 - 28s - loss: 0.7804 - accuracy: 0.7183 - val_loss: 0.8677 - val_accuracy: 0.6857 - 28s/epoch - 20ms/step\n",
      "Epoch 30/100\n",
      "1417/1417 - 28s - loss: 0.7705 - accuracy: 0.7232 - val_loss: 0.8695 - val_accuracy: 0.6851 - 28s/epoch - 20ms/step\n",
      "Epoch 31/100\n",
      "1417/1417 - 29s - loss: 0.7627 - accuracy: 0.7245 - val_loss: 0.8732 - val_accuracy: 0.6793 - 29s/epoch - 21ms/step\n",
      "Epoch 31: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "1417/1417 - 29s - loss: 1.6320 - accuracy: 0.3859 - val_loss: 1.6561 - val_accuracy: 0.3352 - 29s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 1.5747 - accuracy: 0.4135 - val_loss: 1.6899 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 28s - loss: 1.5676 - accuracy: 0.4160 - val_loss: 1.6778 - val_accuracy: 0.3352 - 28s/epoch - 20ms/step\n",
      "Epoch 3: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "1417/1417 - 28s - loss: 1.6332 - accuracy: 0.3873 - val_loss: 1.7004 - val_accuracy: 0.3352 - 28s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 28s - loss: 1.5748 - accuracy: 0.4139 - val_loss: 1.6754 - val_accuracy: 0.3352 - 28s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 1.5668 - accuracy: 0.4156 - val_loss: 1.6852 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 27s - loss: 1.5642 - accuracy: 0.4162 - val_loss: 1.6739 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 27s - loss: 1.5596 - accuracy: 0.4162 - val_loss: 1.6422 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 28s - loss: 1.5506 - accuracy: 0.4169 - val_loss: 1.6226 - val_accuracy: 0.3352 - 28s/epoch - 20ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 28s - loss: 1.4906 - accuracy: 0.4604 - val_loss: 1.4151 - val_accuracy: 0.4955 - 28s/epoch - 20ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 28s - loss: 1.2606 - accuracy: 0.5685 - val_loss: 1.2119 - val_accuracy: 0.5006 - 28s/epoch - 20ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 28s - loss: 1.1918 - accuracy: 0.5790 - val_loss: 1.1611 - val_accuracy: 0.5183 - 28s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "1417/1417 - 28s - loss: 1.1678 - accuracy: 0.5818 - val_loss: 1.1519 - val_accuracy: 0.5026 - 28s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "1417/1417 - 28s - loss: 1.1425 - accuracy: 0.5911 - val_loss: 1.0818 - val_accuracy: 0.5621 - 28s/epoch - 20ms/step\n",
      "Epoch 12/100\n",
      "1417/1417 - 28s - loss: 1.1152 - accuracy: 0.6057 - val_loss: 1.0571 - val_accuracy: 0.6093 - 28s/epoch - 20ms/step\n",
      "Epoch 13/100\n",
      "1417/1417 - 28s - loss: 1.0908 - accuracy: 0.6175 - val_loss: 1.0632 - val_accuracy: 0.5801 - 28s/epoch - 20ms/step\n",
      "Epoch 14/100\n",
      "1417/1417 - 28s - loss: 1.0729 - accuracy: 0.6259 - val_loss: 1.0222 - val_accuracy: 0.6157 - 28s/epoch - 20ms/step\n",
      "Epoch 15/100\n",
      "1417/1417 - 28s - loss: 1.0532 - accuracy: 0.6335 - val_loss: 1.0086 - val_accuracy: 0.6238 - 28s/epoch - 20ms/step\n",
      "Epoch 16/100\n",
      "1417/1417 - 28s - loss: 1.0412 - accuracy: 0.6374 - val_loss: 0.9978 - val_accuracy: 0.6384 - 28s/epoch - 20ms/step\n",
      "Epoch 17/100\n",
      "1417/1417 - 27s - loss: 1.0256 - accuracy: 0.6438 - val_loss: 0.9864 - val_accuracy: 0.6387 - 27s/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "1417/1417 - 26s - loss: 1.0112 - accuracy: 0.6475 - val_loss: 0.9816 - val_accuracy: 0.6336 - 26s/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "1417/1417 - 27s - loss: 0.9958 - accuracy: 0.6562 - val_loss: 0.9518 - val_accuracy: 0.6600 - 27s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "1417/1417 - 27s - loss: 0.9807 - accuracy: 0.6622 - val_loss: 0.9595 - val_accuracy: 0.6414 - 27s/epoch - 19ms/step\n",
      "Epoch 21/100\n",
      "1417/1417 - 27s - loss: 0.9642 - accuracy: 0.6673 - val_loss: 0.9316 - val_accuracy: 0.6640 - 27s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "1417/1417 - 27s - loss: 0.9454 - accuracy: 0.6736 - val_loss: 0.9235 - val_accuracy: 0.6744 - 27s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "1417/1417 - 26s - loss: 0.9217 - accuracy: 0.6812 - val_loss: 0.8987 - val_accuracy: 0.6777 - 26s/epoch - 19ms/step\n",
      "Epoch 24/100\n",
      "1417/1417 - 27s - loss: 0.8896 - accuracy: 0.6916 - val_loss: 0.8848 - val_accuracy: 0.6833 - 27s/epoch - 19ms/step\n",
      "Epoch 25/100\n",
      "1417/1417 - 27s - loss: 0.8522 - accuracy: 0.7021 - val_loss: 0.8893 - val_accuracy: 0.6637 - 27s/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "1417/1417 - 27s - loss: 0.8228 - accuracy: 0.7106 - val_loss: 0.8801 - val_accuracy: 0.6738 - 27s/epoch - 19ms/step\n",
      "Epoch 27/100\n",
      "1417/1417 - 27s - loss: 0.8025 - accuracy: 0.7154 - val_loss: 0.8812 - val_accuracy: 0.6680 - 27s/epoch - 19ms/step\n",
      "Epoch 28/100\n",
      "1417/1417 - 27s - loss: 0.7852 - accuracy: 0.7198 - val_loss: 0.8644 - val_accuracy: 0.6894 - 27s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "1417/1417 - 26s - loss: 0.7754 - accuracy: 0.7222 - val_loss: 0.8738 - val_accuracy: 0.6763 - 26s/epoch - 19ms/step\n",
      "Epoch 30/100\n",
      "1417/1417 - 26s - loss: 0.7655 - accuracy: 0.7241 - val_loss: 0.8625 - val_accuracy: 0.6897 - 26s/epoch - 19ms/step\n",
      "Epoch 31/100\n",
      "1417/1417 - 27s - loss: 0.7589 - accuracy: 0.7256 - val_loss: 0.8657 - val_accuracy: 0.6859 - 27s/epoch - 19ms/step\n",
      "Epoch 32/100\n",
      "1417/1417 - 26s - loss: 0.7515 - accuracy: 0.7281 - val_loss: 0.8617 - val_accuracy: 0.6827 - 26s/epoch - 19ms/step\n",
      "Epoch 32: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "1417/1417 - 29s - loss: 1.6306 - accuracy: 0.3888 - val_loss: 1.6619 - val_accuracy: 0.3352 - 29s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 1.5754 - accuracy: 0.4145 - val_loss: 1.6495 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 1.5672 - accuracy: 0.4160 - val_loss: 1.6484 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 27s - loss: 1.5655 - accuracy: 0.4160 - val_loss: 1.6638 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 27s - loss: 1.5618 - accuracy: 0.4163 - val_loss: 1.6540 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 5: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "1417/1417 - 28s - loss: 1.6305 - accuracy: 0.3886 - val_loss: 1.6600 - val_accuracy: 0.3352 - 28s/epoch - 20ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 1.5753 - accuracy: 0.4124 - val_loss: 1.6606 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 1.5663 - accuracy: 0.4159 - val_loss: 1.6454 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 27s - loss: 1.5643 - accuracy: 0.4158 - val_loss: 1.6555 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 28s - loss: 1.5612 - accuracy: 0.4163 - val_loss: 1.6379 - val_accuracy: 0.3352 - 28s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 27s - loss: 1.5558 - accuracy: 0.4165 - val_loss: 1.6281 - val_accuracy: 0.3352 - 27s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 27s - loss: 1.5277 - accuracy: 0.4333 - val_loss: 1.5425 - val_accuracy: 0.4179 - 27s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 27s - loss: 1.3341 - accuracy: 0.5469 - val_loss: 1.2287 - val_accuracy: 0.5013 - 27s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 27s - loss: 1.2029 - accuracy: 0.5781 - val_loss: 1.1729 - val_accuracy: 0.5033 - 27s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "1417/1417 - 27s - loss: 1.1744 - accuracy: 0.5811 - val_loss: 1.1292 - val_accuracy: 0.5347 - 27s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "1417/1417 - 27s - loss: 1.1512 - accuracy: 0.5875 - val_loss: 1.1042 - val_accuracy: 0.5280 - 27s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "1417/1417 - 27s - loss: 1.1251 - accuracy: 0.5998 - val_loss: 1.0601 - val_accuracy: 0.5682 - 27s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "1417/1417 - 27s - loss: 1.0966 - accuracy: 0.6167 - val_loss: 1.0329 - val_accuracy: 0.6238 - 27s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "1417/1417 - 27s - loss: 1.0768 - accuracy: 0.6247 - val_loss: 1.0350 - val_accuracy: 0.6118 - 27s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "1417/1417 - 27s - loss: 1.0582 - accuracy: 0.6331 - val_loss: 1.0001 - val_accuracy: 0.6251 - 27s/epoch - 19ms/step\n",
      "Epoch 16/100\n",
      "1417/1417 - 27s - loss: 1.0435 - accuracy: 0.6383 - val_loss: 0.9970 - val_accuracy: 0.6234 - 27s/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "1417/1417 - 26s - loss: 1.0262 - accuracy: 0.6442 - val_loss: 0.9866 - val_accuracy: 0.6300 - 26s/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "1417/1417 - 27s - loss: 1.0140 - accuracy: 0.6485 - val_loss: 0.9665 - val_accuracy: 0.6432 - 27s/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "1417/1417 - 27s - loss: 0.9976 - accuracy: 0.6557 - val_loss: 0.9585 - val_accuracy: 0.6583 - 27s/epoch - 19ms/step\n",
      "Epoch 20/100\n",
      "1417/1417 - 28s - loss: 0.9772 - accuracy: 0.6644 - val_loss: 0.9353 - val_accuracy: 0.6572 - 28s/epoch - 19ms/step\n",
      "Epoch 21/100\n",
      "1417/1417 - 27s - loss: 0.9603 - accuracy: 0.6691 - val_loss: 0.9226 - val_accuracy: 0.6625 - 27s/epoch - 19ms/step\n",
      "Epoch 22/100\n",
      "1417/1417 - 27s - loss: 0.9374 - accuracy: 0.6771 - val_loss: 0.9042 - val_accuracy: 0.6722 - 27s/epoch - 19ms/step\n",
      "Epoch 23/100\n",
      "1417/1417 - 27s - loss: 0.9034 - accuracy: 0.6870 - val_loss: 0.8953 - val_accuracy: 0.6791 - 27s/epoch - 19ms/step\n",
      "Epoch 24/100\n",
      "1417/1417 - 27s - loss: 0.8707 - accuracy: 0.6956 - val_loss: 0.8816 - val_accuracy: 0.6861 - 27s/epoch - 19ms/step\n",
      "Epoch 25/100\n",
      "1417/1417 - 27s - loss: 0.8337 - accuracy: 0.7064 - val_loss: 0.8775 - val_accuracy: 0.6806 - 27s/epoch - 19ms/step\n",
      "Epoch 26/100\n",
      "1417/1417 - 27s - loss: 0.8100 - accuracy: 0.7108 - val_loss: 0.8958 - val_accuracy: 0.6587 - 27s/epoch - 19ms/step\n",
      "Epoch 27/100\n",
      "1417/1417 - 27s - loss: 0.7931 - accuracy: 0.7156 - val_loss: 0.8647 - val_accuracy: 0.6973 - 27s/epoch - 19ms/step\n",
      "Epoch 28/100\n",
      "1417/1417 - 26s - loss: 0.7819 - accuracy: 0.7180 - val_loss: 0.8698 - val_accuracy: 0.6868 - 26s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "1417/1417 - 27s - loss: 0.7736 - accuracy: 0.7221 - val_loss: 0.8760 - val_accuracy: 0.6636 - 27s/epoch - 19ms/step\n",
      "Epoch 29: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"models/best_weights_additional.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='sigmoid', input_shape=(1, x_cols, 1), padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='sigmoid', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')\n",
    "    model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot),callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model:  tanh and sgd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "1417/1417 - 27s - loss: 0.8985 - accuracy: 0.6900 - val_loss: 0.9105 - val_accuracy: 0.6443 - 27s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 0.7462 - accuracy: 0.7404 - val_loss: 0.8821 - val_accuracy: 0.6727 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 26s - loss: 0.7189 - accuracy: 0.7478 - val_loss: 0.9006 - val_accuracy: 0.6630 - 26s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 26s - loss: 0.7002 - accuracy: 0.7524 - val_loss: 0.8614 - val_accuracy: 0.6833 - 26s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 27s - loss: 0.6875 - accuracy: 0.7543 - val_loss: 0.8315 - val_accuracy: 0.7039 - 27s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 28s - loss: 0.6749 - accuracy: 0.7555 - val_loss: 0.8395 - val_accuracy: 0.6997 - 28s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 27s - loss: 0.6662 - accuracy: 0.7576 - val_loss: 0.8012 - val_accuracy: 0.7275 - 27s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "1417/1417 - 26s - loss: 0.6586 - accuracy: 0.7579 - val_loss: 0.8104 - val_accuracy: 0.7062 - 26s/epoch - 18ms/step\n",
      "Epoch 9/100\n",
      "1417/1417 - 26s - loss: 0.6529 - accuracy: 0.7603 - val_loss: 0.7968 - val_accuracy: 0.7198 - 26s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "1417/1417 - 26s - loss: 0.6468 - accuracy: 0.7631 - val_loss: 0.8164 - val_accuracy: 0.7013 - 26s/epoch - 18ms/step\n",
      "Epoch 11/100\n",
      "1417/1417 - 26s - loss: 0.6415 - accuracy: 0.7632 - val_loss: 0.8555 - val_accuracy: 0.6920 - 26s/epoch - 18ms/step\n",
      "Epoch 11: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "1417/1417 - 27s - loss: 0.8997 - accuracy: 0.6900 - val_loss: 0.8861 - val_accuracy: 0.6700 - 27s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 26s - loss: 0.7489 - accuracy: 0.7410 - val_loss: 0.9091 - val_accuracy: 0.6692 - 26s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 0.7187 - accuracy: 0.7481 - val_loss: 0.8594 - val_accuracy: 0.6849 - 27s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 26s - loss: 0.6990 - accuracy: 0.7501 - val_loss: 0.8851 - val_accuracy: 0.6747 - 26s/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 26s - loss: 0.6854 - accuracy: 0.7541 - val_loss: 0.8935 - val_accuracy: 0.6733 - 26s/epoch - 19ms/step\n",
      "Epoch 5: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "1417/1417 - 26s - loss: 0.9028 - accuracy: 0.6883 - val_loss: 0.8665 - val_accuracy: 0.6936 - 26s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 26s - loss: 0.7475 - accuracy: 0.7415 - val_loss: 0.9166 - val_accuracy: 0.6461 - 26s/epoch - 18ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 26s - loss: 0.7184 - accuracy: 0.7482 - val_loss: 0.8730 - val_accuracy: 0.6775 - 26s/epoch - 18ms/step\n",
      "Epoch 3: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "1417/1417 - 27s - loss: 0.8909 - accuracy: 0.6912 - val_loss: 0.9018 - val_accuracy: 0.6641 - 27s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 0.7448 - accuracy: 0.7406 - val_loss: 0.9119 - val_accuracy: 0.6617 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 26s - loss: 0.7168 - accuracy: 0.7483 - val_loss: 0.8395 - val_accuracy: 0.6933 - 26s/epoch - 18ms/step\n",
      "Epoch 4/100\n",
      "1417/1417 - 26s - loss: 0.7004 - accuracy: 0.7506 - val_loss: 0.8484 - val_accuracy: 0.6976 - 26s/epoch - 18ms/step\n",
      "Epoch 5/100\n",
      "1417/1417 - 26s - loss: 0.6860 - accuracy: 0.7537 - val_loss: 0.8060 - val_accuracy: 0.7175 - 26s/epoch - 18ms/step\n",
      "Epoch 6/100\n",
      "1417/1417 - 26s - loss: 0.6712 - accuracy: 0.7565 - val_loss: 0.8361 - val_accuracy: 0.7021 - 26s/epoch - 18ms/step\n",
      "Epoch 7/100\n",
      "1417/1417 - 26s - loss: 0.6655 - accuracy: 0.7573 - val_loss: 0.8647 - val_accuracy: 0.6750 - 26s/epoch - 19ms/step\n",
      "Epoch 7: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "1417/1417 - 27s - loss: 0.8904 - accuracy: 0.6907 - val_loss: 0.8753 - val_accuracy: 0.6785 - 27s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "1417/1417 - 27s - loss: 0.7433 - accuracy: 0.7428 - val_loss: 0.8888 - val_accuracy: 0.6666 - 27s/epoch - 19ms/step\n",
      "Epoch 3/100\n",
      "1417/1417 - 27s - loss: 0.7138 - accuracy: 0.7485 - val_loss: 0.8812 - val_accuracy: 0.6759 - 27s/epoch - 19ms/step\n",
      "Epoch 3: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"models/best_weights_additional.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='tanh', input_shape=(1, x_cols, 1), padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='tanh', padding='same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=2, verbose=2, mode='auto')\n",
    "    model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot),callbacks=[monitor, checkpointer], verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load best model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/best_weights_additional.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Weights for best model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_8/kernel:0' shape=(3, 3, 1, 64) dtype=float32, numpy=\n",
       " array([[[[ 5.21252602e-02,  1.42185614e-02, -5.28424047e-02,\n",
       "            8.44657868e-02,  7.51330554e-02, -7.90015906e-02,\n",
       "           -3.80245224e-02, -3.22110876e-02, -9.63411853e-02,\n",
       "           -5.15082143e-02, -2.88085639e-03, -5.63463382e-02,\n",
       "           -2.40157098e-02, -3.40320244e-02, -3.77707258e-02,\n",
       "           -8.74789134e-02, -7.32648671e-02,  6.51351362e-02,\n",
       "           -2.52684057e-02,  4.45061177e-03, -7.46091008e-02,\n",
       "           -8.61137658e-02,  6.39543235e-02, -2.17590854e-02,\n",
       "           -7.35795498e-02,  4.95414287e-02, -7.56813288e-02,\n",
       "           -3.94738615e-02,  2.63992697e-02, -4.27016653e-02,\n",
       "            8.84143412e-02,  4.73531038e-02, -5.40531836e-02,\n",
       "            9.55521762e-02, -5.57775162e-02,  3.65145355e-02,\n",
       "            7.22737610e-03, -2.25680098e-02,  1.64967477e-02,\n",
       "            8.37862045e-02, -9.69599187e-02, -4.34609503e-02,\n",
       "           -3.19905877e-02,  7.84459710e-02,  5.77369332e-02,\n",
       "           -6.68179914e-02, -8.88674036e-02,  9.60467309e-02,\n",
       "            9.61373746e-02,  6.70163482e-02,  5.27148694e-02,\n",
       "           -8.16792622e-02,  9.69333351e-02, -1.66117996e-02,\n",
       "            3.16466391e-03,  7.92181045e-02,  7.19907433e-02,\n",
       "            7.64012039e-02,  3.01626027e-02,  7.07464963e-02,\n",
       "           -3.35486755e-02, -9.66521129e-02,  3.53851169e-02,\n",
       "            8.56284946e-02]],\n",
       " \n",
       "         [[-2.59533450e-02, -9.18675214e-02,  9.95923132e-02,\n",
       "           -9.76972505e-02, -2.85691321e-02, -1.71368271e-02,\n",
       "            5.97120374e-02, -4.49389480e-02, -8.72877017e-02,\n",
       "            5.75238168e-02, -8.18243027e-02, -8.66188854e-03,\n",
       "            8.07386488e-02, -4.81554791e-02,  7.68507421e-02,\n",
       "            1.58899948e-02,  7.77842849e-03,  4.44775969e-02,\n",
       "           -8.08335394e-02, -6.89472258e-02,  5.36593646e-02,\n",
       "           -2.50127017e-02,  8.51479918e-03,  5.48598468e-02,\n",
       "            9.00412351e-02,  7.63608366e-02, -5.35432994e-03,\n",
       "           -8.18028301e-03,  2.67377347e-02, -5.88245690e-02,\n",
       "           -2.18728855e-02, -6.03120811e-02,  6.35406077e-02,\n",
       "            2.13476196e-02,  9.26893204e-02, -9.06772166e-02,\n",
       "            8.34726542e-02,  1.00889608e-01,  2.18689218e-02,\n",
       "            8.30767155e-02, -8.94991010e-02,  1.84629112e-03,\n",
       "           -4.52067479e-02, -9.69474390e-02,  5.40168136e-02,\n",
       "           -7.01050758e-02,  9.21992362e-02, -3.94526124e-02,\n",
       "           -6.15983196e-02, -4.87539284e-02, -7.19107985e-02,\n",
       "           -9.54285264e-04,  2.76921839e-02, -5.64669073e-03,\n",
       "            3.07436585e-02, -7.77182505e-02,  1.17997080e-03,\n",
       "           -2.55153179e-02, -4.48929258e-02, -4.92411144e-02,\n",
       "           -5.45893833e-02,  6.44249767e-02, -1.75103545e-04,\n",
       "           -4.11033966e-02]],\n",
       " \n",
       "         [[ 9.75551456e-03,  7.77272135e-02, -2.55890191e-03,\n",
       "           -7.54896402e-02,  9.59271640e-02,  5.26696146e-02,\n",
       "           -1.78204104e-02,  8.18753690e-02, -5.55303134e-02,\n",
       "           -3.98228839e-02,  6.82921559e-02,  3.48280370e-02,\n",
       "            9.80394632e-02,  5.88657856e-02,  6.40659779e-02,\n",
       "            2.73776501e-02, -3.62932608e-02, -3.88271436e-02,\n",
       "            7.21801221e-02, -2.53207758e-02, -1.70743838e-02,\n",
       "           -1.64966062e-02,  2.03997865e-02,  9.63256359e-02,\n",
       "            8.59915614e-02, -8.83969739e-02,  9.32230949e-02,\n",
       "            1.72510818e-02, -3.91003750e-02,  9.44573730e-02,\n",
       "            6.02354258e-02,  5.46428263e-02, -4.03138623e-02,\n",
       "           -7.56333023e-02, -3.19227353e-02,  2.28163749e-02,\n",
       "           -3.30913067e-03, -4.64943834e-02,  3.32241654e-02,\n",
       "            6.92046434e-03,  2.34666839e-02, -4.54663374e-02,\n",
       "           -6.91548437e-02, -5.88202961e-02, -9.96648073e-02,\n",
       "           -7.65094310e-02, -6.42555356e-02, -6.09359816e-02,\n",
       "            9.14070308e-02,  5.12579978e-02,  8.51814151e-02,\n",
       "           -4.02982384e-02,  3.51329893e-02,  6.01117015e-02,\n",
       "            2.87574232e-02, -1.28509104e-02, -3.46986577e-02,\n",
       "           -1.04907304e-02, -8.04601014e-02,  4.60765958e-02,\n",
       "           -6.47170842e-02,  2.25665644e-02,  6.53604418e-02,\n",
       "            9.51221436e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 4.05723900e-01, -4.52201925e-02,  4.13453102e-01,\n",
       "           -3.01978230e-01,  3.39709908e-01, -1.13971159e-02,\n",
       "           -2.56568789e-02,  4.37362939e-02,  1.10793673e-01,\n",
       "            3.66597146e-01,  2.59400140e-02, -1.47751227e-01,\n",
       "            3.58418822e-02,  1.78942621e-01, -3.32888693e-01,\n",
       "           -1.50050707e-02, -2.40874931e-01,  1.48999572e-01,\n",
       "            1.66535631e-01, -2.23684162e-01,  2.34356239e-01,\n",
       "           -4.20722216e-02, -2.58648098e-01,  2.61526972e-01,\n",
       "           -2.44805869e-02, -1.36314094e-01, -7.65098214e-01,\n",
       "           -2.69091278e-01,  2.50203013e-01, -3.54012877e-01,\n",
       "           -1.74961407e-02,  1.95850898e-02, -1.77517951e-01,\n",
       "           -3.12394172e-01,  2.30745301e-02,  1.21075977e-02,\n",
       "           -4.20129895e-01,  4.71008979e-02, -4.36207652e-01,\n",
       "            3.10921632e-02, -7.30220461e-03, -2.48697940e-02,\n",
       "           -1.79866880e-01,  7.09075212e-01,  5.61038375e-01,\n",
       "            3.94045442e-01,  4.24444139e-01, -3.10764432e-01,\n",
       "            6.26217782e-01,  5.78287899e-01,  2.95447409e-01,\n",
       "            1.95313632e-01, -2.29189888e-01, -3.56509507e-01,\n",
       "            3.59165639e-01, -1.27875283e-01, -5.51600814e-01,\n",
       "            1.61229819e-01,  2.15958178e-01, -3.99547964e-02,\n",
       "           -1.32997349e-01, -1.84205860e-01, -3.07890207e-01,\n",
       "           -3.04481387e-01]],\n",
       " \n",
       "         [[ 1.42102772e-02,  1.31326333e-01, -4.90365177e-02,\n",
       "           -2.84640081e-02,  1.56592689e-02, -1.54135153e-02,\n",
       "           -2.15663612e-01,  1.72851503e-01,  1.46766871e-01,\n",
       "           -1.68899018e-02, -1.35328561e-01, -1.46986125e-02,\n",
       "           -1.94639370e-01,  5.01171313e-02,  1.37567088e-01,\n",
       "           -8.77651945e-02,  1.16308525e-01,  1.24384373e-01,\n",
       "            1.59611516e-02,  1.40889868e-01,  6.23531789e-02,\n",
       "           -1.84833601e-01,  1.94383070e-01, -1.35744050e-01,\n",
       "           -1.23463333e-01, -4.07076925e-02,  1.70064509e-01,\n",
       "           -3.44396569e-02, -2.65368849e-01, -1.52373062e-02,\n",
       "           -6.62566647e-02,  4.68582399e-02, -7.70590827e-02,\n",
       "           -2.45858990e-02,  1.93334535e-01, -1.59498043e-02,\n",
       "            1.64023917e-02,  1.03082493e-01, -1.52191464e-02,\n",
       "            1.73611984e-01,  1.44158453e-02, -2.60885149e-01,\n",
       "           -5.62451109e-02, -6.16864786e-02, -1.82552934e-02,\n",
       "            1.72399953e-02,  1.78671069e-02,  1.47771249e-02,\n",
       "           -1.72345843e-02, -1.94223188e-02,  3.41476463e-02,\n",
       "            3.39900181e-02,  1.63734078e-01,  6.73980415e-02,\n",
       "            2.56619863e-02,  6.58222660e-02, -2.61322912e-02,\n",
       "           -1.29460087e-02, -1.20113930e-02, -1.34882107e-01,\n",
       "           -3.21301036e-02, -1.29799902e-01, -2.82285120e-02,\n",
       "           -1.63924694e-02]],\n",
       " \n",
       "         [[ 1.28920972e-01, -1.69216350e-01, -1.36473039e-02,\n",
       "            1.51991993e-01, -1.57342162e-02, -1.01274237e-01,\n",
       "           -2.86837280e-01, -1.04448181e-02, -1.20467264e-02,\n",
       "           -1.67203434e-02, -2.32855558e-01, -1.74760416e-01,\n",
       "            1.26158334e-02, -8.85891169e-02, -1.48185380e-02,\n",
       "            1.04256310e-02, -1.44710153e-01, -2.49754563e-01,\n",
       "            1.28971338e-02, -1.30637378e-01,  2.86631156e-02,\n",
       "           -2.16071770e-01,  3.94750126e-02, -1.42039377e-02,\n",
       "            1.93868339e-01,  1.94333553e-01, -1.53444484e-01,\n",
       "            2.56989092e-01,  1.46869998e-02,  1.57284401e-02,\n",
       "            8.50201324e-02, -1.23018682e-01,  1.30230207e-02,\n",
       "           -1.65941715e-01,  2.56858319e-01,  7.69957751e-02,\n",
       "           -6.39343634e-02,  2.18639821e-01, -9.76650510e-03,\n",
       "            2.50956088e-01, -1.58007070e-01, -2.10608855e-01,\n",
       "           -1.44882172e-01,  5.14900647e-02, -5.87761141e-02,\n",
       "            1.97096944e-01, -1.65492091e-02,  2.03881308e-01,\n",
       "            1.16876904e-02,  9.90122557e-03,  8.17780569e-02,\n",
       "           -2.31289983e-01,  7.44425058e-02,  1.73457284e-02,\n",
       "            1.35769799e-01,  1.96716264e-01,  1.34187669e-01,\n",
       "            1.49510121e-02, -1.66402180e-02,  1.18483240e-02,\n",
       "           -2.23236024e-01,  1.27785290e-02,  1.92673162e-01,\n",
       "            1.55878905e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 8.70370269e-02, -6.94474205e-02, -3.80546823e-02,\n",
       "           -8.99570957e-02,  3.37979347e-02, -8.24443847e-02,\n",
       "            6.65325671e-02, -8.85932893e-03, -2.84767970e-02,\n",
       "            4.45342511e-02,  3.46031636e-02, -3.72540578e-02,\n",
       "           -7.46681318e-02, -5.63120507e-02, -6.45362586e-02,\n",
       "            7.00673312e-02,  3.01961899e-02, -5.48008531e-02,\n",
       "            9.37926173e-02, -7.79025555e-02, -8.23305920e-02,\n",
       "            4.82798219e-02,  1.04439110e-02,  5.64890355e-02,\n",
       "            5.58716059e-02, -4.81644124e-02, -8.99559855e-02,\n",
       "           -7.52889663e-02, -7.94774741e-02, -3.89490798e-02,\n",
       "           -5.88393956e-03, -5.36391884e-03, -2.01636702e-02,\n",
       "           -7.04917908e-02,  3.95589769e-02, -5.86204678e-02,\n",
       "            6.62936270e-03, -4.56112809e-02,  6.53969198e-02,\n",
       "            7.86279142e-02,  8.77121836e-02, -4.50914986e-02,\n",
       "            9.77821201e-02,  4.89061177e-02, -6.15318939e-02,\n",
       "           -4.63656858e-02, -6.61795810e-02,  9.49449688e-02,\n",
       "            4.56044525e-02,  4.95070517e-02, -7.00577497e-02,\n",
       "           -4.35519293e-02,  9.06841904e-02,  4.06633019e-02,\n",
       "            2.06622258e-02,  6.19842112e-02,  3.86998951e-02,\n",
       "            3.14108580e-02, -9.76850837e-02,  7.60667920e-02,\n",
       "           -6.04332462e-02, -5.45814671e-02, -3.56062949e-02,\n",
       "           -6.83331788e-02]],\n",
       " \n",
       "         [[-4.19478863e-03,  6.07593805e-02,  7.59680569e-03,\n",
       "           -5.23270890e-02,  6.59029633e-02,  3.19257826e-02,\n",
       "            5.48472852e-02, -2.26260126e-02, -7.22371042e-03,\n",
       "            8.90091062e-03, -8.01684484e-02, -4.19086516e-02,\n",
       "           -5.16963564e-02, -3.42511907e-02, -3.02547812e-02,\n",
       "            9.25840139e-02,  5.58234602e-02, -6.04647063e-02,\n",
       "            4.74318564e-02,  6.64551556e-02,  3.66016179e-02,\n",
       "            1.47268996e-02, -3.60993221e-02, -7.62408823e-02,\n",
       "           -5.95876686e-02, -5.78512140e-02, -6.94822147e-02,\n",
       "            9.52712446e-02, -3.05318087e-02,  9.98958498e-02,\n",
       "            3.50706279e-02, -1.32481754e-03, -6.91720694e-02,\n",
       "           -2.50539705e-02,  5.86144030e-02, -1.03124827e-02,\n",
       "            8.09904337e-02, -1.31562576e-02, -1.69828758e-02,\n",
       "           -2.53270790e-02, -7.98261166e-02, -6.15788102e-02,\n",
       "            5.09452820e-02,  5.47938496e-02,  6.39005452e-02,\n",
       "           -9.87537950e-02,  3.20558697e-02, -5.58832027e-02,\n",
       "           -7.37696737e-02, -4.92471270e-02,  6.61674589e-02,\n",
       "            9.57767069e-02, -7.84782842e-02,  6.07582480e-02,\n",
       "            9.46175605e-02, -4.58849482e-02,  3.62395048e-02,\n",
       "            8.83726627e-02,  1.12050772e-02,  3.83539349e-02,\n",
       "           -7.03926682e-02,  2.97178626e-02,  1.93134993e-02,\n",
       "            9.70538706e-02]],\n",
       " \n",
       "         [[-5.27573861e-02, -4.01317067e-02, -1.00218728e-01,\n",
       "            7.54348338e-02,  1.32875815e-02, -6.48147315e-02,\n",
       "           -2.87621021e-02,  1.15599409e-02, -9.15463790e-02,\n",
       "           -8.11034366e-02, -1.49816871e-02, -6.38374388e-02,\n",
       "           -3.20588946e-02,  4.02427763e-02,  1.10313743e-02,\n",
       "            9.08923745e-02, -1.22623369e-02,  6.95388615e-02,\n",
       "           -4.35842127e-02, -7.81578943e-02, -1.00567803e-01,\n",
       "            6.71233535e-02, -4.62106019e-02, -5.89580461e-02,\n",
       "            7.63956308e-02,  1.62157193e-02, -8.41849223e-02,\n",
       "           -7.01843202e-02, -1.32004172e-03,  9.89514440e-02,\n",
       "            1.09060556e-02,  7.60470182e-02,  2.10637152e-02,\n",
       "            2.56574601e-02, -2.69265547e-02, -8.68764296e-02,\n",
       "            5.58141917e-02, -1.01111732e-01, -8.82303715e-02,\n",
       "            2.88487822e-02,  3.13609689e-02,  5.56824356e-02,\n",
       "            8.02891701e-03,  8.33718479e-03,  6.69903606e-02,\n",
       "            2.50476897e-02, -7.21468776e-02, -1.21851936e-02,\n",
       "           -7.63896108e-03, -2.51534507e-02, -6.61819428e-02,\n",
       "           -8.14738572e-02, -9.16349217e-02,  5.90035170e-02,\n",
       "            4.70650941e-02, -5.41744679e-02, -6.48407564e-02,\n",
       "            8.56276751e-02,  2.30431035e-02, -3.64732891e-02,\n",
       "            6.22422844e-02,  3.10470015e-02,  2.52612084e-02,\n",
       "            8.23897719e-02]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_8/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.09358177, -0.0067326 ,  0.10878111, -0.03982837,  0.07526999,\n",
       "         0.00549292, -0.10714046,  0.03717779,  0.02699758,  0.08189729,\n",
       "        -0.06717035, -0.07811988, -0.01891403,  0.01388641, -0.01271191,\n",
       "        -0.01061062, -0.05963546, -0.02285323, -0.02193174, -0.05078809,\n",
       "         0.06006155, -0.05596054, -0.00588209,  0.07304312,  0.0139308 ,\n",
       "         0.05988421, -0.24623552,  0.04564876, -0.07227039, -0.05045944,\n",
       "        -0.02555681, -0.02991528, -0.04086342, -0.11035888,  0.0685332 ,\n",
       "         0.02476939, -0.09679101,  0.04963331, -0.06720053,  0.0890329 ,\n",
       "        -0.00083155, -0.12320893, -0.05097992,  0.21024884,  0.14785753,\n",
       "         0.12647246,  0.08194201, -0.04438841,  0.12000334,  0.14745116,\n",
       "         0.06806783, -0.01828434,  0.03722883, -0.08353053,  0.09456645,\n",
       "         0.04181818, -0.10761373,  0.00747005,  0.0449599 , -0.03088088,\n",
       "        -0.05262062, -0.08921627, -0.00053197, -0.0877235 ], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_9/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
       " array([[[[-0.05815697, -0.01928277, -0.04142101, ..., -0.01175974,\n",
       "           -0.02857535,  0.04498774],\n",
       "          [ 0.04457377,  0.03255307, -0.02213173, ...,  0.01913106,\n",
       "           -0.03175817,  0.04399156],\n",
       "          [-0.03462286, -0.05194513,  0.02170299, ..., -0.02219741,\n",
       "           -0.01418784,  0.01603479],\n",
       "          ...,\n",
       "          [ 0.03654685, -0.05314102, -0.00161327, ..., -0.04236041,\n",
       "           -0.0428466 , -0.01469769],\n",
       "          [-0.00115412, -0.00663775, -0.04548602, ...,  0.03862874,\n",
       "            0.0519275 ,  0.00949477],\n",
       "          [-0.0227447 , -0.04260004,  0.01486415, ..., -0.01336682,\n",
       "            0.03412622, -0.02259074]],\n",
       " \n",
       "         [[-0.03944441, -0.05787067,  0.01609855, ..., -0.04571649,\n",
       "            0.00397227,  0.03932853],\n",
       "          [-0.03696112,  0.02505825,  0.00434839, ...,  0.00807326,\n",
       "           -0.04057931,  0.03151712],\n",
       "          [-0.02932708,  0.03278154,  0.0185794 , ...,  0.04413826,\n",
       "           -0.0528536 ,  0.02323947],\n",
       "          ...,\n",
       "          [ 0.02424512,  0.03870371, -0.00844074, ..., -0.01282798,\n",
       "            0.01535755,  0.04417865],\n",
       "          [ 0.00029236, -0.02709011, -0.01186449, ...,  0.04488818,\n",
       "            0.05340515,  0.05408606],\n",
       "          [-0.03986045, -0.00018559,  0.05081411, ..., -0.02455653,\n",
       "            0.03740318, -0.01015999]],\n",
       " \n",
       "         [[ 0.03259102, -0.02729111, -0.02801821, ...,  0.01624176,\n",
       "           -0.03077448,  0.02414149],\n",
       "          [-0.03326321,  0.05311583, -0.04217111, ..., -0.05873076,\n",
       "           -0.0380046 , -0.00736831],\n",
       "          [-0.01705385,  0.05614719, -0.03755866, ...,  0.0275601 ,\n",
       "           -0.05228303,  0.04925371],\n",
       "          ...,\n",
       "          [ 0.01741676,  0.04376033,  0.03189563, ..., -0.01450807,\n",
       "           -0.05841722, -0.00469155],\n",
       "          [ 0.04200987,  0.01957155,  0.00273508, ..., -0.03926624,\n",
       "           -0.01040056, -0.01195501],\n",
       "          [ 0.02455818,  0.02708702,  0.05466852, ..., -0.02795392,\n",
       "            0.00678782,  0.0281655 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.012941  ,  0.00863168, -0.03717449, ..., -0.02110425,\n",
       "           -0.04881621, -0.05095177],\n",
       "          [-0.03977403,  0.04370891, -0.03253355, ..., -0.05654153,\n",
       "            0.01037201, -0.04391433],\n",
       "          [-0.04225611,  0.01036506,  0.0553023 , ..., -0.03683569,\n",
       "            0.02416222, -0.04238653],\n",
       "          ...,\n",
       "          [-0.04932198, -0.01750125,  0.03549908, ..., -0.02608048,\n",
       "            0.02057185, -0.02228533],\n",
       "          [ 0.03550964,  0.04735243, -0.00028049, ..., -0.03248756,\n",
       "           -0.03795082,  0.00668361],\n",
       "          [-0.00017873,  0.02420068, -0.03581823, ...,  0.04472761,\n",
       "            0.00422458, -0.05650203]],\n",
       " \n",
       "         [[ 0.02521738, -0.04473183, -0.01708749, ...,  0.04941494,\n",
       "           -0.05154639, -0.02673585],\n",
       "          [ 0.0040991 , -0.00272985,  0.02201558, ..., -0.05034941,\n",
       "           -0.03849665,  0.01983183],\n",
       "          [ 0.04362959, -0.07521316,  0.04882672, ..., -0.0165188 ,\n",
       "            0.0216491 , -0.03307038],\n",
       "          ...,\n",
       "          [-0.04643356,  0.04900493, -0.01990224, ..., -0.04280042,\n",
       "            0.02746585,  0.00351787],\n",
       "          [-0.06852849, -0.02502061, -0.03643606, ...,  0.03446499,\n",
       "            0.02879375, -0.02472641],\n",
       "          [-0.01526758,  0.02104736,  0.03766331, ..., -0.01519556,\n",
       "           -0.06251505,  0.01356685]],\n",
       " \n",
       "         [[ 0.00928722, -0.00144174,  0.0397415 , ..., -0.01601371,\n",
       "           -0.01674412, -0.01445775],\n",
       "          [ 0.04360157, -0.00926895, -0.03040938, ...,  0.00679439,\n",
       "           -0.00283781, -0.02072528],\n",
       "          [-0.05131203,  0.04598383,  0.00449327, ..., -0.01516555,\n",
       "           -0.03010085,  0.00556854],\n",
       "          ...,\n",
       "          [-0.03847392, -0.00648889, -0.02045711, ...,  0.02198151,\n",
       "            0.02064461,  0.04212837],\n",
       "          [ 0.04355878,  0.00986109, -0.01285102, ...,  0.03074159,\n",
       "           -0.0091453 , -0.05506482],\n",
       "          [ 0.00380327, -0.00728474,  0.05972458, ..., -0.00629104,\n",
       "            0.01871455, -0.05577264]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05412496,  0.00013819,  0.05273769, ...,  0.04447583,\n",
       "            0.03888476,  0.05674719],\n",
       "          [-0.01704153, -0.02983786, -0.01005096, ...,  0.05795276,\n",
       "           -0.00055836,  0.01464294],\n",
       "          [ 0.00463364, -0.0400278 , -0.00161706, ...,  0.00226175,\n",
       "           -0.02051283,  0.05230292],\n",
       "          ...,\n",
       "          [ 0.02435653,  0.03771817,  0.00922479, ...,  0.01120568,\n",
       "           -0.02730068,  0.0383171 ],\n",
       "          [-0.00526822,  0.02768389, -0.04922381, ..., -0.03128354,\n",
       "            0.00673865, -0.01056147],\n",
       "          [-0.01153107,  0.01421081, -0.02985832, ...,  0.01196732,\n",
       "           -0.04681147,  0.01880439]],\n",
       " \n",
       "         [[ 0.04691232, -0.04735495, -0.01448865, ...,  0.0351312 ,\n",
       "            0.03717255,  0.02204595],\n",
       "          [ 0.02111057,  0.01483702,  0.01683254, ...,  0.02137185,\n",
       "            0.02931214, -0.05820467],\n",
       "          [-0.01870938, -0.0406382 , -0.04136766, ..., -0.00350665,\n",
       "           -0.05768843, -0.03824041],\n",
       "          ...,\n",
       "          [-0.05252663,  0.03419797,  0.00755472, ...,  0.01405072,\n",
       "           -0.022154  ,  0.03703583],\n",
       "          [ 0.01522171,  0.04868047, -0.0586353 , ..., -0.00048376,\n",
       "            0.00433714,  0.02306656],\n",
       "          [ 0.01839634, -0.0075552 , -0.05548895, ...,  0.04033938,\n",
       "           -0.01814724, -0.01786854]],\n",
       " \n",
       "         [[ 0.00853183,  0.03227843,  0.0421504 , ...,  0.00378858,\n",
       "           -0.04165942,  0.05589386],\n",
       "          [-0.04349799,  0.05759659, -0.05090158, ..., -0.04331482,\n",
       "            0.03315922, -0.03722578],\n",
       "          [-0.006432  , -0.00560063, -0.0094042 , ..., -0.03737591,\n",
       "            0.0302036 , -0.00324375],\n",
       "          ...,\n",
       "          [ 0.02322992,  0.00371142,  0.05365903, ...,  0.02653478,\n",
       "            0.02435142,  0.03949667],\n",
       "          [ 0.04154241,  0.01037711, -0.04251135, ...,  0.04841036,\n",
       "           -0.00944316, -0.00676118],\n",
       "          [-0.04537937,  0.03819565, -0.01008949, ..., -0.05563391,\n",
       "           -0.03516074,  0.00538174]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_9/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([ 0.00392603, -0.0034906 ,  0.00907258, -0.00536258,  0.01301307,\n",
       "        -0.01831289,  0.07322628,  0.02284446,  0.00056098,  0.01166865,\n",
       "        -0.06351742, -0.02229558, -0.02485798,  0.00875523,  0.00327322,\n",
       "        -0.00372306,  0.02829592, -0.0051267 ,  0.02332185, -0.02570976,\n",
       "         0.01548959,  0.00497474,  0.00251566,  0.00366577,  0.00548163,\n",
       "        -0.01211205, -0.01043477, -0.01496359, -0.01032434,  0.0134236 ,\n",
       "        -0.00535701, -0.0212107 ,  0.04450131, -0.01475131, -0.00810476,\n",
       "         0.00668439,  0.06546529,  0.00843704,  0.04194662,  0.0148211 ,\n",
       "        -0.0051696 ,  0.00596352, -0.01883991, -0.00367457,  0.05451763,\n",
       "         0.00577284,  0.01528976,  0.01583199,  0.01802761, -0.00972418,\n",
       "        -0.01164279,  0.02273776, -0.00902465,  0.00797168, -0.01538294,\n",
       "        -0.02300218, -0.00352304, -0.00752441,  0.00457874,  0.00952453,\n",
       "        -0.00699589,  0.00880505,  0.00109872, -0.00765351, -0.06461983,\n",
       "         0.00296238,  0.00582299,  0.00703024, -0.13463111,  0.00549038,\n",
       "        -0.01831773, -0.00579327,  0.01696556,  0.00783895, -0.09392087,\n",
       "         0.00499358, -0.00782179, -0.0142615 , -0.00156694, -0.00783344,\n",
       "         0.00217132,  0.14230444,  0.01847838, -0.1449913 ,  0.01842689,\n",
       "         0.00271828,  0.0018001 , -0.00651439,  0.00638582,  0.04318134,\n",
       "        -0.00898759,  0.00263001, -0.01697449, -0.01565306, -0.02047686,\n",
       "         0.00419044,  0.0204024 , -0.01368711, -0.0161364 , -0.00419861,\n",
       "         0.00773888,  0.00449831,  0.04584286, -0.04153085, -0.01234841,\n",
       "         0.00140632, -0.01155165,  0.00178519,  0.00575213, -0.00060171,\n",
       "        -0.00314419,  0.01553344,  0.01703177,  0.0025746 , -0.00280788,\n",
       "         0.01158604,  0.00064879,  0.00258303,  0.00840641, -0.00945826,\n",
       "         0.00393788,  0.02023764, -0.00172918,  0.00459439,  0.00959161,\n",
       "        -0.00400102, -0.0018967 ,  0.02418582], dtype=float32)>,\n",
       " <tf.Variable 'dense_8/kernel:0' shape=(5376, 1024) dtype=float32, numpy=\n",
       " array([[-0.02283873,  0.00312395,  0.01459721, ...,  0.01518424,\n",
       "          0.01215109, -0.02751248],\n",
       "        [ 0.02595811, -0.01209166,  0.02012723, ..., -0.02738886,\n",
       "          0.0046729 ,  0.02961663],\n",
       "        [-0.01368404, -0.01902534,  0.01335552, ..., -0.00194586,\n",
       "         -0.00050925, -0.01805179],\n",
       "        ...,\n",
       "        [ 0.01421881,  0.0080668 ,  0.00347906, ...,  0.01233394,\n",
       "          0.02655223, -0.01062985],\n",
       "        [-0.02466835, -0.0246393 ,  0.00498777, ...,  0.00662052,\n",
       "         -0.02029593, -0.0104117 ],\n",
       "        [ 0.01477538, -0.01340108, -0.019864  , ..., -0.01162005,\n",
       "         -0.00256352, -0.00296867]], dtype=float32)>,\n",
       " <tf.Variable 'dense_8/bias:0' shape=(1024,) dtype=float32, numpy=\n",
       " array([-6.9854781e-04, -5.0768314e-04,  4.0862178e-03, ...,\n",
       "         2.1534433e-06,  9.2952439e-05,  1.7479229e-03], dtype=float32)>,\n",
       " <tf.Variable 'dense_9/kernel:0' shape=(1024, 9) dtype=float32, numpy=\n",
       " array([[ 0.08814785,  0.0528416 , -0.02442017, ..., -0.04516155,\n",
       "          0.00303858, -0.08299062],\n",
       "        [-0.02337012,  0.0442453 ,  0.02541786, ..., -0.03919175,\n",
       "         -0.059337  ,  0.04426725],\n",
       "        [ 0.04498943,  0.0177982 ,  0.06269484, ..., -0.0416536 ,\n",
       "         -0.02292566, -0.03973478],\n",
       "        ...,\n",
       "        [-0.02804875,  0.00706898,  0.02406929, ..., -0.00121294,\n",
       "          0.03961672,  0.04382826],\n",
       "        [-0.05684981,  0.05851613,  0.03106024, ...,  0.07265827,\n",
       "          0.07950345,  0.07038227],\n",
       "        [ 0.06842078, -0.03742726,  0.06064012, ..., -0.00155592,\n",
       "         -0.05958897, -0.00458148]], dtype=float32)>,\n",
       " <tf.Variable 'dense_9/bias:0' shape=(9,) dtype=float32, numpy=\n",
       " array([-0.01885519, -0.01806557,  0.03674022,  0.1176945 ,  0.01807254,\n",
       "         0.0092508 , -0.02019016, -0.05669971, -0.0679472 ], dtype=float32)>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Best model summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 1, 42, 64)         640       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 1, 42, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 1, 42, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 1, 42, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 5376)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1024)              5506048   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 9)                 9225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5589769 (21.32 MB)\n",
      "Trainable params: 5589769 (21.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Prediction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 9s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test)\n",
    "prediction_labels = np.argmax(prediction, axis=1)\n",
    "y_labels = np.argmax(y_test_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Accuracy score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mt.accuracy_score(y_labels, prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *Precision score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "precision = mt.precision_score(y_labels, prediction_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *F1 score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = mt.f1_score(y_labels, prediction_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Classification Report*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Reconnaissance       0.00      0.00      0.00      2000\n",
      "      Backdoor       0.00      0.00      0.00      1746\n",
      "           DoS       0.37      0.00      0.00     12264\n",
      "      Exploits       0.28      1.00      0.44     33393\n",
      "      Analysis       0.00      0.00      0.00     18184\n",
      "       Fuzzers       0.00      0.00      0.00     40000\n",
      "         Worms       0.00      0.00      0.00     10491\n",
      "     Shellcode       0.00      0.00      0.00      1133\n",
      "       Generic       0.00      0.00      0.00       130\n",
      "\n",
      "      accuracy                           0.28    119341\n",
      "     macro avg       0.07      0.11      0.05    119341\n",
      "  weighted avg       0.12      0.28      0.12    119341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\cdub6\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class_names = [index_to_category[i] for i in range(len(index_to_category))]\n",
    "print(mt.classification_report(y_labels, prediction_labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Root Mean Squared Error (RMSE)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.39504027366638184\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mt.mean_squared_error(prediction, y_test_one_hot))\n",
    "print('RMSE: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Confusion matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0  2000     0     0     0     0     0]\n",
      " [    0     0     0  1746     0     0     0     0     0]\n",
      " [    0     0    13 12251     0     0     0     0     0]\n",
      " [    0     0    20 33373     0     0     0     0     0]\n",
      " [    0     0     0 18184     0     0     0     0     0]\n",
      " [    0     0     2 39998     0     0     0     0     0]\n",
      " [    0     0     0 10491     0     0     0     0     0]\n",
      " [    0     0     0  1133     0     0     0     0     0]\n",
      " [    0     0     0   130     0     0     0     0     0]]\n",
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagnosis = encode_text_index(training_df, 'attack_cat')\n",
    "\n",
    "#y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
    "#binary_prediction_labels = np.argmax(binary_prediction, axis=1)\n",
    "cm = confusion_matrix(y_labels, prediction_labels)\n",
    "print(cm)\n",
    "\n",
    "print('Plotting confusion matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, diagnosis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Regression lift chart*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(prediction_labels, y_labels, sort=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
