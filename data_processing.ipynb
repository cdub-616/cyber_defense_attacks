{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cyber Defense Attacks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Libraries and functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Data Origin*\n",
    "<p>https://research.unsw.edu.au/projects/unsw-nb15-dataset</p>\n",
    "<p>UNSW_NB15_training-set.csv</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Set <bound method NDFrame.head of           id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0          1  0.000011   udp       -   INT      2      0     496       0   \n",
      "1          2  0.000008   udp       -   INT      2      0    1762       0   \n",
      "2          3  0.000005   udp       -   INT      2      0    1068       0   \n",
      "3          4  0.000006   udp       -   INT      2      0     900       0   \n",
      "4          5  0.000010   udp       -   INT      2      0    2126       0   \n",
      "...      ...       ...   ...     ...   ...    ...    ...     ...     ...   \n",
      "82327  82328  0.000005   udp       -   INT      2      0     104       0   \n",
      "82328  82329  1.106101   tcp       -   FIN     20      8   18062     354   \n",
      "82329  82330  0.000000   arp       -   INT      1      0      46       0   \n",
      "82330  82331  0.000000   arp       -   INT      1      0      46       0   \n",
      "82331  82332  0.000009   udp       -   INT      2      0     104       0   \n",
      "\n",
      "                rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0       90909.090200  ...                 1               2             0   \n",
      "1      125000.000300  ...                 1               2             0   \n",
      "2      200000.005100  ...                 1               3             0   \n",
      "3      166666.660800  ...                 1               3             0   \n",
      "4      100000.002500  ...                 1               3             0   \n",
      "...              ...  ...               ...             ...           ...   \n",
      "82327  200000.005100  ...                 1               2             0   \n",
      "82328      24.410067  ...                 1               1             0   \n",
      "82329       0.000000  ...                 1               1             0   \n",
      "82330       0.000000  ...                 1               1             0   \n",
      "82331  111111.107200  ...                 1               1             0   \n",
      "\n",
      "       ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0               0                 0           1           2                0   \n",
      "1               0                 0           1           2                0   \n",
      "2               0                 0           1           3                0   \n",
      "3               0                 0           2           3                0   \n",
      "4               0                 0           2           3                0   \n",
      "...           ...               ...         ...         ...              ...   \n",
      "82327           0                 0           2           1                0   \n",
      "82328           0                 0           3           2                0   \n",
      "82329           0                 0           1           1                1   \n",
      "82330           0                 0           1           1                1   \n",
      "82331           0                 0           1           1                0   \n",
      "\n",
      "       attack_cat  label  \n",
      "0          Normal      0  \n",
      "1          Normal      0  \n",
      "2          Normal      0  \n",
      "3          Normal      0  \n",
      "4          Normal      0  \n",
      "...           ...    ...  \n",
      "82327      Normal      0  \n",
      "82328      Normal      0  \n",
      "82329      Normal      0  \n",
      "82330      Normal      0  \n",
      "82331      Normal      0  \n",
      "\n",
      "[82332 rows x 45 columns]>\n"
     ]
    }
   ],
   "source": [
    "training_set_df = pd.read_csv('data/UNSW_NB15_testing-set.csv');\n",
    "print('Original Training Set', training_set_df.head);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>UNSW_NB15_testing-set.csv</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Testing Set <bound method NDFrame.head of             id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0            1  0.121478   tcp       -   FIN      6      4     258     172   \n",
      "1            2  0.649902   tcp       -   FIN     14     38     734   42014   \n",
      "2            3  1.623129   tcp       -   FIN      8     16     364   13186   \n",
      "3            4  1.681642   tcp     ftp   FIN     12     12     628     770   \n",
      "4            5  0.449454   tcp       -   FIN     10      6     534     268   \n",
      "...        ...       ...   ...     ...   ...    ...    ...     ...     ...   \n",
      "175336  175337  0.000009   udp     dns   INT      2      0     114       0   \n",
      "175337  175338  0.505762   tcp       -   FIN     10      8     620     354   \n",
      "175338  175339  0.000009   udp     dns   INT      2      0     114       0   \n",
      "175339  175340  0.000009   udp     dns   INT      2      0     114       0   \n",
      "175340  175341  0.000009   udp     dns   INT      2      0     114       0   \n",
      "\n",
      "                 rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0           74.087490  ...                 1               1             0   \n",
      "1           78.473372  ...                 1               2             0   \n",
      "2           14.170161  ...                 1               3             0   \n",
      "3           13.677108  ...                 1               3             1   \n",
      "4           33.373826  ...                 1              40             0   \n",
      "...               ...  ...               ...             ...           ...   \n",
      "175336  111111.107200  ...                13              24             0   \n",
      "175337      33.612649  ...                 1               2             0   \n",
      "175338  111111.107200  ...                 3              13             0   \n",
      "175339  111111.107200  ...                14              30             0   \n",
      "175340  111111.107200  ...                16              30             0   \n",
      "\n",
      "        ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0                0                 0           1           1                0   \n",
      "1                0                 0           1           6                0   \n",
      "2                0                 0           2           6                0   \n",
      "3                1                 0           2           1                0   \n",
      "4                0                 0           2          39                0   \n",
      "...            ...               ...         ...         ...              ...   \n",
      "175336           0                 0          24          24                0   \n",
      "175337           0                 0           1           1                0   \n",
      "175338           0                 0           3          12                0   \n",
      "175339           0                 0          30          30                0   \n",
      "175340           0                 0          30          30                0   \n",
      "\n",
      "        attack_cat  label  \n",
      "0           Normal      0  \n",
      "1           Normal      0  \n",
      "2           Normal      0  \n",
      "3           Normal      0  \n",
      "4           Normal      0  \n",
      "...            ...    ...  \n",
      "175336     Generic      1  \n",
      "175337   Shellcode      1  \n",
      "175338     Generic      1  \n",
      "175339     Generic      1  \n",
      "175340     Generic      1  \n",
      "\n",
      "[175341 rows x 45 columns]>\n"
     ]
    }
   ],
   "source": [
    "testing_set_df = pd.read_csv('data/UNSW_NB15_training-set.csv');\n",
    "print('Original Testing Set', testing_set_df.head);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Compare column headings in each set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training columns: Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
      "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
      "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
      "      dtype='object') length: 45\n",
      "testing columns: Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
      "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
      "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
      "      dtype='object') length: 45\n",
      "just in training: [] length: 0\n",
      "just in testing: [] length: 0\n"
     ]
    }
   ],
   "source": [
    "unique_columns_training = training_set_df.columns.unique();\n",
    "unique_columns_testing = testing_set_df.columns.unique();\n",
    "print('training columns:', unique_columns_training, 'length:', len(unique_columns_training));\n",
    "print('testing columns:', unique_columns_testing, 'length:', len(unique_columns_testing));\n",
    "print('just in training:', [x for x in unique_columns_training if x not in unique_columns_testing], 'length:', len([x for x in unique_columns_training if x not in unique_columns_testing]));\n",
    "print('just in testing:', [x for x in unique_columns_testing if x not in unique_columns_training], 'length:', len([x for x in unique_columns_testing if x not in unique_columns_training]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Both files share the same categorical values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Remove unnecessary columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_df.drop(['id', 'attack_cat'], axis=1, inplace=True);\n",
    "testing_set_df.drop(['id', 'attack_cat'], axis=1, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Remove rows with missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set after dropna <bound method NDFrame.head of             dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0      0.000011   udp       -   INT      2      0     496       0   \n",
      "1      0.000008   udp       -   INT      2      0    1762       0   \n",
      "2      0.000005   udp       -   INT      2      0    1068       0   \n",
      "3      0.000006   udp       -   INT      2      0     900       0   \n",
      "4      0.000010   udp       -   INT      2      0    2126       0   \n",
      "...         ...   ...     ...   ...    ...    ...     ...     ...   \n",
      "82327  0.000005   udp       -   INT      2      0     104       0   \n",
      "82328  1.106101   tcp       -   FIN     20      8   18062     354   \n",
      "82329  0.000000   arp       -   INT      1      0      46       0   \n",
      "82330  0.000000   arp       -   INT      1      0      46       0   \n",
      "82331  0.000009   udp       -   INT      2      0     104       0   \n",
      "\n",
      "                rate  sttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
      "0       90909.090200   254  ...                 1                 1   \n",
      "1      125000.000300   254  ...                 1                 1   \n",
      "2      200000.005100   254  ...                 1                 1   \n",
      "3      166666.660800   254  ...                 2                 1   \n",
      "4      100000.002500   254  ...                 2                 1   \n",
      "...              ...   ...  ...               ...               ...   \n",
      "82327  200000.005100   254  ...                 1                 1   \n",
      "82328      24.410067   254  ...                 1                 1   \n",
      "82329       0.000000     0  ...                 1                 1   \n",
      "82330       0.000000     0  ...                 1                 1   \n",
      "82331  111111.107200   254  ...                 1                 1   \n",
      "\n",
      "       ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  \\\n",
      "0                   2             0           0                 0           1   \n",
      "1                   2             0           0                 0           1   \n",
      "2                   3             0           0                 0           1   \n",
      "3                   3             0           0                 0           2   \n",
      "4                   3             0           0                 0           2   \n",
      "...               ...           ...         ...               ...         ...   \n",
      "82327               2             0           0                 0           2   \n",
      "82328               1             0           0                 0           3   \n",
      "82329               1             0           0                 0           1   \n",
      "82330               1             0           0                 0           1   \n",
      "82331               1             0           0                 0           1   \n",
      "\n",
      "       ct_srv_dst  is_sm_ips_ports  label  \n",
      "0               2                0      0  \n",
      "1               2                0      0  \n",
      "2               3                0      0  \n",
      "3               3                0      0  \n",
      "4               3                0      0  \n",
      "...           ...              ...    ...  \n",
      "82327           1                0      0  \n",
      "82328           2                0      0  \n",
      "82329           1                1      0  \n",
      "82330           1                1      0  \n",
      "82331           1                0      0  \n",
      "\n",
      "[82332 rows x 43 columns]>\n",
      "Training set shape: (82332, 43)\n"
     ]
    }
   ],
   "source": [
    "training_set_df.dropna(inplace=True);\n",
    "print('Training Set after dropna', training_set_df.head);\n",
    "print('Training set shape:', training_set_df.shape);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set after dropna <bound method NDFrame.head of              dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0       0.121478   tcp       -   FIN      6      4     258     172   \n",
      "1       0.649902   tcp       -   FIN     14     38     734   42014   \n",
      "2       1.623129   tcp       -   FIN      8     16     364   13186   \n",
      "3       1.681642   tcp     ftp   FIN     12     12     628     770   \n",
      "4       0.449454   tcp       -   FIN     10      6     534     268   \n",
      "...          ...   ...     ...   ...    ...    ...     ...     ...   \n",
      "175336  0.000009   udp     dns   INT      2      0     114       0   \n",
      "175337  0.505762   tcp       -   FIN     10      8     620     354   \n",
      "175338  0.000009   udp     dns   INT      2      0     114       0   \n",
      "175339  0.000009   udp     dns   INT      2      0     114       0   \n",
      "175340  0.000009   udp     dns   INT      2      0     114       0   \n",
      "\n",
      "                 rate  sttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
      "0           74.087490   252  ...                 1                 1   \n",
      "1           78.473372    62  ...                 1                 1   \n",
      "2           14.170161    62  ...                 1                 1   \n",
      "3           13.677108    62  ...                 1                 1   \n",
      "4           33.373826   254  ...                 2                 1   \n",
      "...               ...   ...  ...               ...               ...   \n",
      "175336  111111.107200   254  ...                24                13   \n",
      "175337      33.612649   254  ...                 1                 1   \n",
      "175338  111111.107200   254  ...                 3                 3   \n",
      "175339  111111.107200   254  ...                30                14   \n",
      "175340  111111.107200   254  ...                30                16   \n",
      "\n",
      "        ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  \\\n",
      "0                    1             0           0                 0   \n",
      "1                    2             0           0                 0   \n",
      "2                    3             0           0                 0   \n",
      "3                    3             1           1                 0   \n",
      "4                   40             0           0                 0   \n",
      "...                ...           ...         ...               ...   \n",
      "175336              24             0           0                 0   \n",
      "175337               2             0           0                 0   \n",
      "175338              13             0           0                 0   \n",
      "175339              30             0           0                 0   \n",
      "175340              30             0           0                 0   \n",
      "\n",
      "        ct_src_ltm  ct_srv_dst  is_sm_ips_ports  label  \n",
      "0                1           1                0      0  \n",
      "1                1           6                0      0  \n",
      "2                2           6                0      0  \n",
      "3                2           1                0      0  \n",
      "4                2          39                0      0  \n",
      "...            ...         ...              ...    ...  \n",
      "175336          24          24                0      1  \n",
      "175337           1           1                0      1  \n",
      "175338           3          12                0      1  \n",
      "175339          30          30                0      1  \n",
      "175340          30          30                0      1  \n",
      "\n",
      "[175341 rows x 43 columns]>\n",
      "Testing set shape: (175341, 43)\n"
     ]
    }
   ],
   "source": [
    "testing_set_df.dropna(inplace=True);\n",
    "print('Testing Set after dropna', testing_set_df.head);\n",
    "print('Testing set shape:', testing_set_df.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Encode categorical features one-hot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n",
      "C:\\Users\\cdub6\\AppData\\Local\\Temp\\ipykernel_11372\\1098474453.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[dummy_name] = dummies[x]\n"
     ]
    }
   ],
   "source": [
    "training_one_hot = training_set_df.copy();\n",
    "testing_one_hot = testing_set_df.copy();\n",
    "for column in training_one_hot.select_dtypes(include=['object']).columns: \n",
    "    encode_text_dummy(training_one_hot, column);\n",
    "    encode_text_dummy(testing_one_hot, column);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Encode categorical features index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_index = training_set_df.copy();\n",
    "testing_index = testing_set_df.copy();\n",
    "for column in training_index.select_dtypes(include=['object']).columns: \n",
    "    encode_text_index(training_index, column);\n",
    "    encode_text_index(testing_index, column);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Normalize numeric features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in training_set_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    encode_numeric_zscore(training_one_hot, column);\n",
    "    encode_numeric_zscore(testing_one_hot, column);\n",
    "    encode_numeric_zscore(training_index, column);\n",
    "    encode_numeric_zscore(testing_index, column);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Training one-hot set after encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n",
      "0     -0.213726 -0.124454 -0.151815 -0.043683 -0.087368  0.057181  0.719436   \n",
      "1     -0.213727 -0.124454 -0.151815 -0.036308 -0.087368  0.286563  0.719436   \n",
      "2     -0.213727 -0.124454 -0.151815 -0.040351 -0.087368  0.791205  0.719436   \n",
      "3     -0.213727 -0.124454 -0.151815 -0.041330 -0.087368  0.566919  0.719436   \n",
      "4     -0.213726 -0.124454 -0.151815 -0.034187 -0.087368  0.118349  0.719436   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "82327 -0.213727 -0.124454 -0.151815 -0.045967 -0.087368  0.791205  0.719436   \n",
      "82328  0.021090  0.009958 -0.082596  0.058657 -0.085031 -0.554342  0.719436   \n",
      "82329 -0.213728 -0.131922 -0.151815 -0.046305 -0.087368 -0.554506 -1.782698   \n",
      "82330 -0.213728 -0.131922 -0.151815 -0.046305 -0.087368 -0.554506 -1.782698   \n",
      "82331 -0.213727 -0.124454 -0.151815 -0.045967 -0.087368  0.193111  0.719436   \n",
      "\n",
      "           dttl     sload     dload  ...  service-snmp  service-ssh  \\\n",
      "0     -0.820390  0.643909 -0.263496  ...         False        False   \n",
      "1     -0.820390  4.539323 -0.263496  ...         False        False   \n",
      "2     -0.820390  4.391432 -0.263496  ...         False        False   \n",
      "3     -0.820390  2.977013 -0.263496  ...         False        False   \n",
      "4     -0.820390  4.369193 -0.263496  ...         False        False   \n",
      "...         ...       ...       ...  ...           ...          ...   \n",
      "82327 -0.820390  0.103696 -0.263496  ...         False        False   \n",
      "82328  1.339591 -0.358191 -0.262559  ...         False        False   \n",
      "82329 -0.820390 -0.358881 -0.263496  ...         False        False   \n",
      "82330 -0.820390 -0.358881 -0.263496  ...         False        False   \n",
      "82331 -0.820390 -0.101894 -0.263496  ...         False        False   \n",
      "\n",
      "       service-ssl  state-ACC  state-CLO  state-CON  state-FIN  state-INT  \\\n",
      "0            False      False      False      False      False       True   \n",
      "1            False      False      False      False      False       True   \n",
      "2            False      False      False      False      False       True   \n",
      "3            False      False      False      False      False       True   \n",
      "4            False      False      False      False      False       True   \n",
      "...            ...        ...        ...        ...        ...        ...   \n",
      "82327        False      False      False      False      False       True   \n",
      "82328        False      False      False      False       True      False   \n",
      "82329        False      False      False      False      False       True   \n",
      "82330        False      False      False      False      False       True   \n",
      "82331        False      False      False      False      False       True   \n",
      "\n",
      "       state-REQ  state-RST  \n",
      "0          False      False  \n",
      "1          False      False  \n",
      "2          False      False  \n",
      "3          False      False  \n",
      "4          False      False  \n",
      "...          ...        ...  \n",
      "82327      False      False  \n",
      "82328      False      False  \n",
      "82329      False      False  \n",
      "82330      False      False  \n",
      "82331      False      False  \n",
      "\n",
      "[82332 rows x 191 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(training_one_hot.head);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing one-hot set after encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n",
      "0      -0.191028 -0.104456 -0.135768 -0.049133 -0.102725 -0.576370  0.703837   \n",
      "1      -0.109484 -0.046013  0.172598 -0.046410  0.188544 -0.576343 -1.141898   \n",
      "2       0.040699 -0.089845 -0.026933 -0.048527 -0.012133 -0.576732 -1.141898   \n",
      "3       0.049729 -0.060624 -0.063212 -0.047016 -0.098562 -0.576735 -1.141898   \n",
      "4      -0.140417 -0.075234 -0.117629 -0.047554 -0.102057 -0.576616  0.723266   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "175336 -0.209773 -0.133677 -0.172047 -0.049957 -0.103923  0.094951  0.723266   \n",
      "175337 -0.131727 -0.075234 -0.099490 -0.047062 -0.101458 -0.576614  0.723266   \n",
      "175338 -0.209773 -0.133677 -0.172047 -0.049957 -0.103923  0.094951  0.723266   \n",
      "175339 -0.209773 -0.133677 -0.172047 -0.049957 -0.103923  0.094951  0.723266   \n",
      "175340 -0.209773 -0.133677 -0.172047 -0.049957 -0.103923  0.094951  0.723266   \n",
      "\n",
      "            dttl     sload     dload  ...  service-ssl  state-CON  state-ECO  \\\n",
      "0       1.578096 -0.389896 -0.273699  ...        False      False      False   \n",
      "1       1.559998 -0.389927 -0.069233  ...        False      False      False   \n",
      "2       1.559998 -0.389963 -0.252044  ...        False      False      False   \n",
      "3       1.559998 -0.389957 -0.275820  ...        False      False      False   \n",
      "4       1.559998 -0.389926 -0.275561  ...        False      False      False   \n",
      "...          ...       ...       ...  ...          ...        ...        ...   \n",
      "175336 -0.720404 -0.120979 -0.277207  ...        False      False      False   \n",
      "175337  1.559998 -0.389925 -0.275182  ...        False      False      False   \n",
      "175338 -0.720404 -0.120979 -0.277207  ...        False      False      False   \n",
      "175339 -0.720404 -0.120979 -0.277207  ...        False      False      False   \n",
      "175340 -0.720404 -0.120979 -0.277207  ...        False      False      False   \n",
      "\n",
      "        state-FIN  state-INT  state-PAR  state-REQ  state-RST  state-URN  \\\n",
      "0            True      False      False      False      False      False   \n",
      "1            True      False      False      False      False      False   \n",
      "2            True      False      False      False      False      False   \n",
      "3            True      False      False      False      False      False   \n",
      "4            True      False      False      False      False      False   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "175336      False       True      False      False      False      False   \n",
      "175337       True      False      False      False      False      False   \n",
      "175338      False       True      False      False      False      False   \n",
      "175339      False       True      False      False      False      False   \n",
      "175340      False       True      False      False      False      False   \n",
      "\n",
      "        state-no  \n",
      "0          False  \n",
      "1          False  \n",
      "2          False  \n",
      "3          False  \n",
      "4          False  \n",
      "...          ...  \n",
      "175336     False  \n",
      "175337     False  \n",
      "175338     False  \n",
      "175339     False  \n",
      "175340     False  \n",
      "\n",
      "[175341 rows x 195 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(testing_one_hot.head);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Training index set after encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             dur  proto  service  state     spkts     dpkts    sbytes  \\\n",
      "0     -0.213726    117        0      4 -0.124454 -0.151815 -0.043683   \n",
      "1     -0.213727    117        0      4 -0.124454 -0.151815 -0.036308   \n",
      "2     -0.213727    117        0      4 -0.124454 -0.151815 -0.040351   \n",
      "3     -0.213727    117        0      4 -0.124454 -0.151815 -0.041330   \n",
      "4     -0.213726    117        0      4 -0.124454 -0.151815 -0.034187   \n",
      "...         ...    ...      ...    ...       ...       ...       ...   \n",
      "82327 -0.213727    117        0      4 -0.124454 -0.151815 -0.045967   \n",
      "82328  0.021090    111        0      3  0.009958 -0.082596  0.058657   \n",
      "82329 -0.213728      6        0      4 -0.131922 -0.151815 -0.046305   \n",
      "82330 -0.213728      6        0      4 -0.131922 -0.151815 -0.046305   \n",
      "82331 -0.213727    117        0      4 -0.124454 -0.151815 -0.045967   \n",
      "\n",
      "         dbytes      rate      sttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
      "0     -0.087368  0.057181  0.719436  ...         -0.468309         -0.450184   \n",
      "1     -0.087368  0.286563  0.719436  ...         -0.468309         -0.450184   \n",
      "2     -0.087368  0.791205  0.719436  ...         -0.468309         -0.450184   \n",
      "3     -0.087368  0.566919  0.719436  ...         -0.349113         -0.450184   \n",
      "4     -0.087368  0.118349  0.719436  ...         -0.349113         -0.450184   \n",
      "...         ...       ...       ...  ...               ...               ...   \n",
      "82327 -0.087368  0.791205  0.719436  ...         -0.468309         -0.450184   \n",
      "82328 -0.085031 -0.554342  0.719436  ...         -0.468309         -0.450184   \n",
      "82329 -0.087368 -0.554506 -1.782698  ...         -0.468309         -0.450184   \n",
      "82330 -0.087368 -0.554506 -1.782698  ...         -0.468309         -0.450184   \n",
      "82331 -0.087368  0.193111  0.719436  ...         -0.468309         -0.450184   \n",
      "\n",
      "       ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  \\\n",
      "0           -0.477991     -0.090857   -0.090617         -0.203142   -0.640029   \n",
      "1           -0.477991     -0.090857   -0.090617         -0.203142   -0.640029   \n",
      "2           -0.390389     -0.090857   -0.090617         -0.203142   -0.640029   \n",
      "3           -0.390389     -0.090857   -0.090617         -0.203142   -0.522987   \n",
      "4           -0.390389     -0.090857   -0.090617         -0.203142   -0.522987   \n",
      "...               ...           ...         ...               ...         ...   \n",
      "82327       -0.477991     -0.090857   -0.090617         -0.203142   -0.522987   \n",
      "82328       -0.565594     -0.090857   -0.090617         -0.203142   -0.405944   \n",
      "82329       -0.565594     -0.090857   -0.090617         -0.203142   -0.640029   \n",
      "82330       -0.565594     -0.090857   -0.090617         -0.203142   -0.640029   \n",
      "82331       -0.565594     -0.090857   -0.090617         -0.203142   -0.640029   \n",
      "\n",
      "       ct_srv_dst  is_sm_ips_ports     label  \n",
      "0       -0.644186        -0.106069 -1.106876  \n",
      "1       -0.644186        -0.106069 -1.106876  \n",
      "2       -0.554270        -0.106069 -1.106876  \n",
      "3       -0.554270        -0.106069 -1.106876  \n",
      "4       -0.554270        -0.106069 -1.106876  \n",
      "...           ...              ...       ...  \n",
      "82327   -0.734103        -0.106069 -1.106876  \n",
      "82328   -0.644186        -0.106069 -1.106876  \n",
      "82329   -0.734103         9.427673 -1.106876  \n",
      "82330   -0.734103         9.427673 -1.106876  \n",
      "82331   -0.734103        -0.106069 -1.106876  \n",
      "\n",
      "[82332 rows x 43 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(training_index.head);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing index set after encoding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              dur  proto  service  state     spkts     dpkts    sbytes  \\\n",
      "0      -0.191028    113        0      2 -0.104456 -0.135768 -0.049133   \n",
      "1      -0.109484    113        0      2 -0.046013  0.172598 -0.046410   \n",
      "2       0.040699    113        0      2 -0.089845 -0.026933 -0.048527   \n",
      "3       0.049729    113        3      2 -0.060624 -0.063212 -0.047016   \n",
      "4      -0.140417    113        0      2 -0.075234 -0.117629 -0.047554   \n",
      "...          ...    ...      ...    ...       ...       ...       ...   \n",
      "175336 -0.209773    119        2      3 -0.133677 -0.172047 -0.049957   \n",
      "175337 -0.131727    113        0      2 -0.075234 -0.099490 -0.047062   \n",
      "175338 -0.209773    119        2      3 -0.133677 -0.172047 -0.049957   \n",
      "175339 -0.209773    119        2      3 -0.133677 -0.172047 -0.049957   \n",
      "175340 -0.209773    119        2      3 -0.133677 -0.172047 -0.049957   \n",
      "\n",
      "          dbytes      rate      sttl  ...  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
      "0      -0.102725 -0.576370  0.703837  ...         -0.544735         -0.554372   \n",
      "1       0.188544 -0.576343 -1.141898  ...         -0.544735         -0.554372   \n",
      "2      -0.012133 -0.576732 -1.141898  ...         -0.544735         -0.554372   \n",
      "3      -0.098562 -0.576735 -1.141898  ...         -0.544735         -0.554372   \n",
      "4      -0.102057 -0.576616  0.723266  ...         -0.420467         -0.554372   \n",
      "...          ...       ...       ...  ...               ...               ...   \n",
      "175336 -0.103923  0.094951  0.723266  ...          2.313436          1.520466   \n",
      "175337 -0.101458 -0.576614  0.723266  ...         -0.544735         -0.554372   \n",
      "175338 -0.103923  0.094951  0.723266  ...         -0.296198         -0.208565   \n",
      "175339 -0.103923  0.094951  0.723266  ...          3.059046          1.693369   \n",
      "175340 -0.103923  0.094951  0.723266  ...          3.059046          2.039175   \n",
      "\n",
      "        ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  \\\n",
      "0            -0.705527     -0.118590   -0.118590         -0.189768   \n",
      "1            -0.614254     -0.118590   -0.118590         -0.189768   \n",
      "2            -0.522981     -0.118590   -0.118590         -0.189768   \n",
      "3            -0.522981      7.814893    7.814893         -0.189768   \n",
      "4             2.854106     -0.118590   -0.118590         -0.189768   \n",
      "...                ...           ...         ...               ...   \n",
      "175336        1.393744     -0.118590   -0.118590         -0.189768   \n",
      "175337       -0.614254     -0.118590   -0.118590         -0.189768   \n",
      "175338        0.389745     -0.118590   -0.118590         -0.189768   \n",
      "175339        1.941380     -0.118590   -0.118590         -0.189768   \n",
      "175340        1.941380     -0.118590   -0.118590         -0.189768   \n",
      "\n",
      "        ct_src_ltm  ct_srv_dst  is_sm_ips_ports     label  \n",
      "0        -0.715712   -0.753072        -0.126508 -1.459821  \n",
      "1        -0.715712   -0.288256        -0.126508 -1.459821  \n",
      "2        -0.595541   -0.288256        -0.126508 -1.459821  \n",
      "3        -0.595541   -0.753072        -0.126508 -1.459821  \n",
      "4        -0.595541    2.779527        -0.126508 -1.459821  \n",
      "...            ...         ...              ...       ...  \n",
      "175336    2.048216    1.385080        -0.126508  0.685012  \n",
      "175337   -0.715712   -0.753072        -0.126508  0.685012  \n",
      "175338   -0.475370    0.269523        -0.126508  0.685012  \n",
      "175339    2.769240    1.942859        -0.126508  0.685012  \n",
      "175340    2.769240    1.942859        -0.126508  0.685012  \n",
      "\n",
      "[175341 rows x 43 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(testing_index.head);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save dataframes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_one_hot.to_pickle('data/training_one_hot.pkl');\n",
    "testing_one_hot.to_pickle('data/testing_one_hot.pkl');\n",
    "training_index.to_pickle('data/training_index.pkl');\n",
    "testing_index.to_pickle('data/testing_index.pkl');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
